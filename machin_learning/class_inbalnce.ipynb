{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d6e7bdc",
   "metadata": {},
   "source": [
    "#### 불균형 클래스\n",
    "#### 클래스 불균형에 대한 이해\n",
    "#### 클래스 가중치를 사용하는 방법\n",
    "#### 리셈플링 기법\n",
    "#### 적절한 평가지표"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb83f1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "악성 양성의 오리지널 비율 : (array([0, 1]), array([212, 357]))\n",
      "클래스 분포 : \n",
      "클래스 0 : 63개 (15.0%)\n",
      "클래스 1 : 357개 (85.0%)\n",
      "1. 기본모델(불균형 무시함)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        악성 0       1.00      0.85      0.92        13\n",
      "        양성 1       0.97      1.00      0.99        71\n",
      "\n",
      "    accuracy                           0.98        84\n",
      "   macro avg       0.99      0.92      0.95        84\n",
      "weighted avg       0.98      0.98      0.98        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 불균형데이터 생성 (1:9 비율) 악성0 : 양성1\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(43) # 값을 고정 (?)\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X , y = data.data , data.target\n",
    "\n",
    "# 악성을 소수 클래스로 생성\n",
    "\n",
    "print(f'악성 양성의 오리지널 비율 : {np.unique(y,return_counts=True)}')\n",
    "m_index = np.where(y==0)[0] #악성index # where는 필터링하여 index를 반환하는 것. index 위치에 해당하는 x도 똑같이 가져와야하기 떄문에 index 번호를 알아야해서.where\n",
    "b_index = np.where(y==1)[0] #양성index\n",
    "\n",
    "# 악성은 일부만 사용할꺼고 양성은 더 많이 사용할꺼임.\n",
    "# 악성의 30% 만 사용 , 양성은 전체 1.5 : 8.5\n",
    "size_30 = int(len(m_index)*0.3)\n",
    "select_m_index = np.random.choice(m_index , size=size_30 , replace=False)\n",
    "select_b_index = b_index\n",
    "# len(select_b_index) / len(select_m_index) + len(select_b_index) # 362.666\n",
    "\n",
    "concatenate_select_index = np.concatenate( [select_m_index , select_b_index] ) #2개를 합칠때 concatenate()\n",
    "np.random.shuffle(concatenate_select_index) # concatenate_select_index 자체를 랜덤하게 섞는것. ( 섞어서 반환하는거 아님;)\n",
    "\n",
    "X_imb = X[concatenate_select_index]\n",
    "y_imb = y[concatenate_select_index]\n",
    "\n",
    "# 클래스 분포 확인\n",
    "unique , counts = np.unique(y_imb,return_counts=True)\n",
    "print('클래스 분포 : ')\n",
    "for label , count in zip(unique , counts):\n",
    "    percentage = count / len(y_imb)*100\n",
    "    print(f'클래스 {label} : {count}개 ({percentage:.1f}%)')\n",
    "\n",
    "\n",
    "\n",
    "# 불균형인 상태로 진행\n",
    "# 스케일링 정규화 StandardScaler\n",
    "# LogisticRegression\n",
    "# pipe\n",
    "# 평가는 class report\n",
    "\n",
    "x_train, x_test , y_train , y_test = train_test_split(X_imb , y_imb , test_size=0.2 , random_state=42, stratify=y_imb)\n",
    "print(f'1. 기본모델(불균형 무시함)')\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('clf', LogisticRegression(random_state=42 , max_iter=1000))\n",
    "])\n",
    "pipe.fit(x_train, y_train)\n",
    "print(classification_report(y_test , pipe.predict(x_test),target_names=['악성 0','양성 1']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d7e3b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불균형 해결 : 클래스 가중치 사용\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        악성 0       0.86      0.92      0.89        13\n",
      "        양성 1       0.99      0.97      0.98        71\n",
      "\n",
      "    accuracy                           0.96        84\n",
      "   macro avg       0.92      0.95      0.93        84\n",
      "weighted avg       0.97      0.96      0.96        84\n",
      "\n",
      "가중치 계산\n",
      "클래스 : 0 : 3.360\n",
      "클래스 : 1 : 0.587\n"
     ]
    }
   ],
   "source": [
    "print('불균형 해결 : 클래스 가중치 사용')\n",
    "\n",
    "# 기존 파이프라인의 clf 이름의 객체의 파라메터를 조정\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "pipe_weight = deepcopy(pipe)\n",
    "pipe_weight.set_params(clf__class_weight = 'balanced') # 언더바언더바?\n",
    "pipe_weight.fit(x_train ,  y_train)\n",
    "print( classification_report(y_test , pipe_weight.predict(x_test),target_names=['악성 0','양성 1'])) \n",
    "\n",
    "print('가중치 계산')\n",
    "n_sample = len(y_train)\n",
    "n_classes = 2\n",
    "class_counts = np.bincount(y_train)\n",
    "for i in range(n_classes):\n",
    "    weight = n_sample / (n_classes * class_counts[i])\n",
    "    print(f'클래스 : {i} : {weight:.3f}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310bb1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불균형 : RandomForest (균형모드)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.81        13\n",
      "           1       0.97      0.96      0.96        71\n",
      "\n",
      "    accuracy                           0.94        84\n",
      "   macro avg       0.88      0.90      0.89        84\n",
      "weighted avg       0.94      0.94      0.94        84\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# RandomForest 균형모드로 만들기.\n",
    "print('불균형 : RandomForest (균형모드)')\n",
    "pipe_rf = Pipeline([\n",
    "    ('scaler',StandardScaler()),\n",
    "    ('clf', RandomForestClassifier(class_weight='balanced' , random_state=43 , n_estimators=100)) # n_estimators=100개가지\n",
    "])\n",
    "# 랜덤포레스트에서 class_weight = 'balanced' 가중치 제거하면 score가 올라감 \n",
    "pipe_rf.fit(x_train,y_train)\n",
    "y_pred = pipe_rf.predict(x_test)\n",
    "print( classification_report(y_test , y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ddf090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling\n",
    "# undersampling\n",
    "# SMOT , SMOTEEN\n",
    "# 과적합을 잡아보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63b1fcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d07376",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
