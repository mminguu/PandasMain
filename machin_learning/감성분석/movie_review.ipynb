{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ccd293a8",
   "metadata": {},
   "source": [
    "#### 감성분석은 머신러닝을 사용\n",
    "    - 데이터셋 : 전처리를 하고\n",
    "    - Bow 모델 : 단어를 특성 벡터로 변환\n",
    "        - tf-idf 단어 적합성 평가\n",
    "        - 텍스트 데이터 정제\n",
    "        - 문서를 토큰으로 나누기\n",
    "        - LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee468f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋\n",
    "# D:\\pandas_main\\machin_learning\\감성분석\\aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a91c6775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in d:\\pandas_main\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy in d:\\pandas_main\\.venv\\lib\\site-packages (2.3.4)\n",
      "Requirement already satisfied: scikit-learn in d:\\pandas_main\\.venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\pandas_main\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\pandas_main\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\pandas_main\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in d:\\pandas_main\\.venv\\lib\\site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in d:\\pandas_main\\.venv\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in d:\\pandas_main\\.venv\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\pandas_main\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9ae1e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Once again Mr. Costner has dragged out a movie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This is an example of why the majority of acti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First of all I hate those moronic rappers, who...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not even the Beatles could write songs everyon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Brass pictures (movies is not a fitting word f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  target\n",
       "0  Once again Mr. Costner has dragged out a movie...       0\n",
       "1  This is an example of why the majority of acti...       0\n",
       "2  First of all I hate those moronic rappers, who...       0\n",
       "3  Not even the Beatles could write songs everyon...       0\n",
       "4  Brass pictures (movies is not a fitting word f...       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from glob import glob\n",
    "file_lists = glob('D:/pandas_main/machin_learning/감성분석/data/movie/neg/*.txt')\n",
    "pd_lists = []\n",
    "for file_path in file_lists[:100]:\n",
    "    with open(file_path,'r' , encoding='utf-8')as f:\n",
    "        data ={\n",
    "            'review' : f.read(),\n",
    "            'target' : 0\n",
    "        }\n",
    "        df = pd.DataFrame([data])\n",
    "        pd_lists.append(df)\n",
    "train_neg_df = pd.concat(pd_lists , ignore_index=True)\n",
    "train_neg_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a876864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\0_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10000_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10001_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10002_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10003_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10004_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10005_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10006_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10007_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10008_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10009_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1000_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10010_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10011_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10012_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10013_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10014_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10015_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10016_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10017_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10018_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10019_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1001_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10020_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10021_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10022_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10023_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10024_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10025_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10026_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10027_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10028_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10029_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1002_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10030_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10031_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10032_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10033_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10034_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10035_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10036_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10037_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10038_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10039_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1003_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10040_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10041_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10042_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10043_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10044_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10045_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10046_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10047_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10048_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10049_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1004_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10050_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10051_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10052_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10053_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10054_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10055_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10056_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10057_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10058_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10059_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1005_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10060_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10061_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10062_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10063_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10064_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10065_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10066_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10067_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10068_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10069_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1006_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10070_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10071_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10072_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10073_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10074_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10075_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10076_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10077_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10078_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10079_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1007_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10080_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10081_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10082_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10083_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10084_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10085_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10086_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10087_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10088_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10089_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1008_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10090_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10091_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10092_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10093_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10094_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10095_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10096_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10097_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10098_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10099_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1009_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\100_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10100_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10101_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10102_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10103_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10104_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10105_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10106_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10107_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10108_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10109_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1010_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10110_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10111_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10112_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10113_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10114_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10115_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10116_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10117_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10118_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10119_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1011_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10120_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10121_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10122_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10123_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10124_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10125_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10126_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10127_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10128_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10129_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1012_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10130_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10131_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10132_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10133_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10134_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10135_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10136_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10137_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10138_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10139_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1013_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10140_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10141_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10142_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10143_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10144_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10145_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10146_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10147_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10148_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10149_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1014_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10150_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10151_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10152_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10153_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10154_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10155_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10156_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10157_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10158_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10159_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1015_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10160_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10161_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10162_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10163_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10164_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10165_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10166_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10167_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10168_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10169_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1016_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10170_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10171_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10172_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10173_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10174_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10175_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10176_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10177_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10178_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10179_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1017_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10180_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10181_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10182_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10183_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10184_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10185_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10186_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10187_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10188_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10189_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1018_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10190_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10191_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10192_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10193_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10194_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10195_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10196_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10197_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10198_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10199_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1019_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\101_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10200_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10201_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10202_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10203_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10204_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10205_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10206_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10207_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10208_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10209_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1020_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10210_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10211_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10212_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10213_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10214_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10215_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10216_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10217_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10218_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10219_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1021_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10220_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10221_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10222_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10223_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10224_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10225_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10226_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10227_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10228_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10229_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1022_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10230_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10231_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10232_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10233_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10234_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10235_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10236_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10237_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10238_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10239_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1023_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10240_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10241_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10242_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10243_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10244_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10245_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10246_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10247_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10248_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10249_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1024_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10250_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10251_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10252_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10253_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10254_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10255_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10256_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10257_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10258_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10259_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1025_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10260_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10261_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10262_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10263_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10264_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10265_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10266_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10267_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10268_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10269_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1026_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10270_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10271_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10272_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10273_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10274_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10275_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10276_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10277_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10278_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10279_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1027_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10280_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10281_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10282_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10283_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10284_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10285_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10286_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10287_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10288_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10289_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1028_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10290_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10291_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10292_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10293_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10294_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10295_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10296_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10297_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10298_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10299_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1029_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\102_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10300_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10301_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10302_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10303_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10304_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10305_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10306_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10307_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10308_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10309_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1030_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10310_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10311_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10312_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10313_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10314_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10315_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10316_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10317_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10318_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10319_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1031_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10320_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10321_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10322_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10323_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10324_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10325_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10326_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10327_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10328_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10329_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1032_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10330_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10331_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10332_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10333_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10334_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10335_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10336_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10337_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10338_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10339_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1033_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10340_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10341_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10342_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10343_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10344_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10345_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10346_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10347_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10348_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10349_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1034_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10350_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10351_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10352_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10353_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10354_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10355_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10356_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10357_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10358_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10359_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1035_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10360_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10361_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10362_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10363_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10364_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10365_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10366_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10367_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10368_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10369_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1036_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10370_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10371_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10372_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10373_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10374_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10375_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10376_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10377_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10378_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10379_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1037_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10380_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10381_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10382_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10383_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10384_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10385_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10386_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10387_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10388_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10389_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1038_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10390_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10391_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10392_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10393_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10394_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10395_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10396_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10397_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10398_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10399_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1039_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\103_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10400_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10401_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10402_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10403_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10404_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10405_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10406_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10407_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10408_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10409_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1040_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10410_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10411_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10412_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10413_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10414_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10415_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10416_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10417_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10418_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10419_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1041_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10420_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10421_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10422_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10423_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10424_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10425_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10426_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10427_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10428_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10429_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1042_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10430_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10431_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10432_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10433_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10434_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10435_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10436_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10437_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10438_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10439_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1043_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10440_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10441_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10442_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10443_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10444_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10445_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10446_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10447_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10448_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10449_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1044_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10450_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10451_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10452_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10453_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10454_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10455_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10456_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10457_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10458_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10459_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1045_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10460_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10461_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10462_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10463_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10464_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10465_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10466_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10467_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10468_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10469_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1046_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10470_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10471_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10472_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10473_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10474_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10475_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10476_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10477_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10478_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10479_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1047_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10480_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10481_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10482_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10483_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10484_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10485_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10486_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10487_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10488_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10489_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1048_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10490_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10491_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10492_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10493_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10494_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10495_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10496_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10497_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10498_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10499_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1049_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\104_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10500_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10501_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10502_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10503_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10504_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10505_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10506_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10507_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10508_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10509_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1050_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10510_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10511_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10512_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10513_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10514_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10515_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10516_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10517_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10518_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10519_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1051_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10520_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10521_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10522_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10523_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10524_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10525_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10526_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10527_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10528_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10529_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1052_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10530_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10531_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10532_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10533_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10534_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10535_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10536_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10537_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10538_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10539_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1053_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10540_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10541_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10542_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10543_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10544_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10545_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10546_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10547_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10548_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10549_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1054_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10550_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10551_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10552_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10553_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10554_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10555_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10556_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10557_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10558_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10559_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1055_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10560_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10561_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10562_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10563_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10564_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10565_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10566_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10567_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10568_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10569_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1056_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10570_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10571_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10572_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10573_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10574_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10575_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10576_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10577_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10578_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10579_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1057_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10580_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10581_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10582_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10583_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10584_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10585_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10586_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10587_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10588_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10589_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1058_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10590_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10591_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10592_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10593_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10594_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10595_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10596_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10597_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10598_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10599_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1059_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\105_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10600_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10601_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10602_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10603_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10604_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10605_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10606_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10607_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10608_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10609_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1060_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10610_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10611_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10612_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10613_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10614_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10615_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10616_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10617_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10618_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10619_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1061_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10620_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10621_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10622_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10623_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10624_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10625_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10626_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10627_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10628_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10629_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1062_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10630_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10631_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10632_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10633_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10634_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10635_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10636_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10637_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10638_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10639_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1063_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10640_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10641_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10642_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10643_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10644_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10645_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10646_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10647_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10648_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10649_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1064_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10650_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10651_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10652_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10653_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10654_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10655_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10656_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10657_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10658_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10659_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1065_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10660_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10661_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10662_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10663_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10664_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10665_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10666_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10667_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10668_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10669_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1066_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10670_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10671_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10672_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10673_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10674_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10675_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10676_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10677_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10678_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10679_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1067_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10680_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10681_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10682_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10683_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10684_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10685_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10686_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10687_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10688_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10689_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1068_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10690_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10691_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10692_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10693_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10694_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10695_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10696_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10697_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10698_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10699_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1069_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\106_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10700_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10701_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10702_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10703_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10704_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10705_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10706_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10707_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10708_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10709_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1070_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10710_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10711_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10712_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10713_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10714_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10715_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10716_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10717_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10718_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10719_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1071_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10720_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10721_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10722_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10723_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10724_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10725_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10726_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10727_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10728_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10729_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1072_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10730_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10731_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10732_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10733_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10734_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10735_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10736_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10737_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10738_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10739_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1073_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10740_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10741_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10742_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10743_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10744_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10745_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10746_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10747_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10748_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10749_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1074_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10750_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10751_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10752_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10753_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10754_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10755_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10756_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10757_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10758_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10759_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1075_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10760_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10761_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10762_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10763_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10764_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10765_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10766_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10767_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10768_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10769_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1076_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10770_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10771_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10772_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10773_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10774_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10775_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10776_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10777_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10778_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10779_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1077_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10780_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10781_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10782_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10783_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10784_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10785_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10786_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10787_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10788_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10789_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1078_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10790_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10791_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10792_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10793_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10794_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10795_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10796_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10797_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10798_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10799_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1079_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\107_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10800_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10801_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10802_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10803_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10804_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10805_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10806_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10807_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10808_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10809_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1080_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10810_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10811_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10812_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10813_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10814_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10815_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10816_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10817_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10818_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10819_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1081_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10820_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10821_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10822_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10823_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10824_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10825_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10826_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10827_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10828_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10829_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1082_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10830_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10831_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10832_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10833_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10834_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10835_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10836_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10837_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10838_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10839_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1083_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10840_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10841_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10842_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10843_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10844_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10845_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10846_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10847_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10848_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10849_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1084_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10850_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10851_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10852_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10853_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10854_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10855_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10856_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10857_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10858_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10859_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1085_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10860_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10861_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10862_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10863_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10864_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10865_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10866_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10867_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10868_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10869_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1086_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10870_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10871_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10872_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10873_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10874_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10875_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10876_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10877_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10878_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10879_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1087_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10880_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10881_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10882_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10883_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10884_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10885_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10886_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10887_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10888_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10889_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1088_3.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10890_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10891_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10892_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10893_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10894_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10895_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10896_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10897_4.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10898_2.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\10899_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\1089_1.txt',\n",
       " 'D:/pandas_main/machin_learning/감성분석/data/movie/neg\\\\108_2.txt',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "glob('D:/pandas_main/machin_learning/감성분석/data/movie/neg/*.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ffe9350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  target\n",
       "0  I went and saw this movie last night after bei...       1\n",
       "1  Actor turned director Bill Paxton follows up h...       1\n",
       "2  As a recreational golfer with some knowledge o...       1\n",
       "3  I saw this film in a sneak preview, and it is ...       1\n",
       "4  Bill Paxton has taken the true story of the 19...       1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positive 동일하게 train_pos_df\n",
    "# train_df = pd.concat({train_neg_df, train_pos_df})\n",
    "# moive_data.csv 로 저장\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "file_lists = glob('D:/pandas_main/machin_learning/감성분석/data/movie/pos/*.txt')\n",
    "pd_lists = []\n",
    "for file_path in file_lists[:100]:\n",
    "    with open(file_path,'r' , encoding='utf-8')as f:\n",
    "        data ={\n",
    "            'review' : f.read(),\n",
    "            'target' : 1\n",
    "        }\n",
    "        df = pd.DataFrame([data])\n",
    "        pd_lists.append(df)\n",
    "train_pos_df = pd.concat(pd_lists , ignore_index=True)\n",
    "train_pos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "346f1d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  target\n",
       "0  I went and saw this movie last night after bei...       1\n",
       "1  Actor turned director Bill Paxton follows up h...       1\n",
       "2  As a recreational golfer with some knowledge o...       1\n",
       "3  I saw this film in a sneak preview, and it is ...       1\n",
       "4  Bill Paxton has taken the true story of the 19...       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([train_pos_df , train_neg_df] , ignore_index=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a52f45ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('movie_data.csv' , index=False , encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7948f124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  target\n",
       "0  I went and saw this movie last night after bei...       1\n",
       "1  Actor turned director Bill Paxton follows up h...       1\n",
       "2  As a recreational golfer with some knowledge o...       1\n",
       "3  I saw this film in a sneak preview, and it is ...       1\n",
       "4  Bill Paxton has taken the true story of the 19...       1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('movie_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a76d57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BOW (bag of Wors) 모델\n",
    "# 문자를 숫자벡터로 바꿔주는 모델\n",
    "# 단어의 등장횟수를 카운트\n",
    "# 전체 훈련데이터에서 모든 고유한 단어(토큰)로 어휘 사전\n",
    "# 리뷰데이터를 사전을 기준으로 벡터화 N번째 단어가 문서에서 3번 나오면 벡터의 N번째 값이 3이 된다.\n",
    "# 사전 : {'나는' : 0 , '영화가' : 1 , '좋다' : 2 , '싫다' : 3} \n",
    "# 문서 1 : \"나는 영화가 좋다\"\n",
    "# 문서 2 : \"나는 영화가 싫다\"\n",
    "# 문서 백터1 : [0,1,2] -> [1,1,1,0]\n",
    "# 문서 백터2 : [0,1,3] -> [1,1,0,1]\n",
    "# CountVectorizer 라는걸로 구별한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e856e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 4, 'sun': 2, 'is': 0, 'shining': 1, 'weather': 5, 'sweet': 3}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "\n",
    "count = CountVectorizer()\n",
    "docs = np.array( [  # numpy 형식으로 해줘야함\n",
    "\n",
    "    \" The sun is shining\",\n",
    "    \" The weather is sweet\"\n",
    "\n",
    "] )\n",
    "count.fit_transform(docs)\n",
    "\n",
    "count.vocabulary_ # 문장에 따른 숫자는 지 멋대로 설정함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb5679f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어의 등장 횟수만 세서 숫자로 표현하는 게 ***** BOW 모델 ***********\n",
    "# 문서 d 에 등장한 단어 f 의 횟수를 tf ( t,d )\n",
    "# BOW 를 보완하면서 좀 더 정교한 텍스트 벡터화 방식 : TF-IDF (Term Frequency Inverse Document Frequency)를 사용\n",
    "# TF : 특정 문서에서 자주 등장함\n",
    "# IDF : TF 와 반대 / 전체 문서에 드물게 등장하는 단어\n",
    "# 특정 문서에서 자주 등장하지만, 전체 문서에서는 드물게 등장하는 단어에 노ㅠ은 가중치를 부여 -> 그 문장을 잘 대표하는 핵심 단어를 찾는다\n",
    "\n",
    "# TF(t,d)  :  단어 t 가 문장 d 에 나타난 횟수 / 문서의 d 의 모든 단어 수\n",
    "# IDF(t,d) :  log ( 총 문서 수 |d| / 단어 t 를 포함한 문서의 수 df(t) )  -> log를 씌우는 이유는 단어의 희귀성을 과하게 반영하지 않도록 스케일링해주는 역할 \n",
    "\n",
    "# 분모에 + 1(사이킷런의 경우) :  분모가 0되는 것을 방지\n",
    "# log( 1+ |D| / 1+df(f)  )\n",
    "\n",
    "#TF-IDF(t,d,D) = TF(t,d) x IDF(t,D)\n",
    "\n",
    "# \"나는\"\n",
    "# TF : 리뷰에 3번 나옴 (높음)\n",
    "# IDF : 전체 10,000개 리뷰중에 9000개 나옴(매우 낮음)\n",
    "# tf-idf  높음 x 매우낮음 = 낮음(중요도가 낮음)\n",
    "\n",
    "# \"명작\"이라는 단어 \n",
    "# TF : 리뷰에 2번 나옴 (높음)\n",
    "# IDF : 전체 10,000개 리뷰중에 50개 나옴(매우 높음)\n",
    "# tf-idf  높음 x 매우높음 = 높음(핵심단어)\n",
    "# 전체 문서 집합(corpus)”을 기준으로, 각 문서(document) 안의 단어 중요도를 계산하는 방식\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39ce09de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater (which was sold out) was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge.\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 정제 : 데이터 정제는 손상되거나 부정확한 레코드를 감지·수정·제거해 데이터의 신뢰도를 높이는 과정\n",
    "# html tag 같은 불필요한 string , 특수 기호 기타 등등 을 제거\n",
    "\n",
    "df.review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5caa3e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 영문 , 공백 .(점) ,(쉼표) 를 제외한 단어를 제거하는 정규표현식 (하이픈 , 숫자 , 밑줄 등 모두 제거합니다.)\n",
    "\n",
    "import re\n",
    "def preprocessor(s):\n",
    "    s = df.review[0]\n",
    "    clean = re.sub(r'[^A-Za-z\\s.,]+', '',s) # 영문자, 공백, 마침표, 쉼표 이외의 모든 문자를 제거\n",
    "    clean = re.sub(r'\\.{2,}','.',clean)\n",
    "    clean = re.sub(r'\\s+',' ',clean).strip()\n",
    "    return clean\n",
    "\n",
    "df['review'] = df.review.apply(preprocessor)\n",
    "\n",
    "#| 예시                        | 결과                |\n",
    "#| --------------------------- | ------------------- |\n",
    "#|`\"강아지🐶 loves snacks!!!!\"`| `\"loves snacks.\"`   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "050ec144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.3.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting joblib (from nltk)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2025.10.23-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting colorama (from click->nltk)\n",
      "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Downloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 63.3 MB/s  0:00:00\n",
      "Downloading regex-2025.10.23-cp313-cp313-win_amd64.whl (276 kB)\n",
      "Downloading click-8.3.0-py3-none-any.whl (107 kB)\n",
      "Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: regex, joblib, colorama, tqdm, click, nltk\n",
      "\n",
      "  Attempting uninstall: regex\n",
      "\n",
      "    Found existing installation: regex 2025.10.23\n",
      "\n",
      "    Uninstalling regex-2025.10.23:\n",
      "\n",
      "      Successfully uninstalled regex-2025.10.23\n",
      "\n",
      "   ---------------------------------------- 0/6 [regex]\n",
      "  Attempting uninstall: joblib\n",
      "   ---------------------------------------- 0/6 [regex]\n",
      "    Found existing installation: joblib 1.5.2\n",
      "   ---------------------------------------- 0/6 [regex]\n",
      "    Uninstalling joblib-1.5.2:\n",
      "   ---------------------------------------- 0/6 [regex]\n",
      "      Successfully uninstalled joblib-1.5.2\n",
      "   ---------------------------------------- 0/6 [regex]\n",
      "   ------ --------------------------------- 1/6 [joblib]\n",
      "   ------ --------------------------------- 1/6 [joblib]\n",
      "   ------ --------------------------------- 1/6 [joblib]\n",
      "   ------ --------------------------------- 1/6 [joblib]\n",
      "   ------ --------------------------------- 1/6 [joblib]\n",
      "  Attempting uninstall: colorama\n",
      "   ------ --------------------------------- 1/6 [joblib]\n",
      "    Found existing installation: colorama 0.4.6\n",
      "   ------ --------------------------------- 1/6 [joblib]\n",
      "    Uninstalling colorama-0.4.6:\n",
      "   ------ --------------------------------- 1/6 [joblib]\n",
      "      Successfully uninstalled colorama-0.4.6\n",
      "   ------ --------------------------------- 1/6 [joblib]\n",
      "   ------------- -------------------------- 2/6 [colorama]\n",
      "  Attempting uninstall: tqdm\n",
      "   ------------- -------------------------- 2/6 [colorama]\n",
      "    Found existing installation: tqdm 4.67.1\n",
      "   ------------- -------------------------- 2/6 [colorama]\n",
      "    Uninstalling tqdm-4.67.1:\n",
      "   ------------- -------------------------- 2/6 [colorama]\n",
      "      Successfully uninstalled tqdm-4.67.1\n",
      "   ------------- -------------------------- 2/6 [colorama]\n",
      "   -------------------- ------------------- 3/6 [tqdm]\n",
      "   -------------------- ------------------- 3/6 [tqdm]\n",
      "  Attempting uninstall: click\n",
      "   -------------------- ------------------- 3/6 [tqdm]\n",
      "    Found existing installation: click 8.3.0\n",
      "   -------------------- ------------------- 3/6 [tqdm]\n",
      "    Uninstalling click-8.3.0:\n",
      "   -------------------- ------------------- 3/6 [tqdm]\n",
      "      Successfully uninstalled click-8.3.0\n",
      "   -------------------- ------------------- 3/6 [tqdm]\n",
      "   -------------------------- ------------- 4/6 [click]\n",
      "   -------------------------- ------------- 4/6 [click]\n",
      "  Attempting uninstall: nltk\n",
      "   -------------------------- ------------- 4/6 [click]\n",
      "    Found existing installation: nltk 3.9.2\n",
      "   -------------------------- ------------- 4/6 [click]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "    Uninstalling nltk-3.9.2:\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "      Successfully uninstalled nltk-3.9.2\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   --------------------------------- ------ 5/6 [nltk]\n",
      "   ---------------------------------------- 6/6 [nltk]\n",
      "\n",
      "Successfully installed click-8.3.0 colorama-0.4.6 joblib-1.5.2 nltk-3.9.2 regex-2025.10.23 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install -U nltk\n",
    "# 자연어(사람이 쓰는 언어)를 컴퓨터가 이해하도록 도와주는 파이썬 라이브러리\n",
    "%pip install --no-cache-dir --upgrade --force-reinstall nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa0df457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "ps = PorterStemmer()\n",
    "print(ps.stem(\"running\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de81cd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\playdata\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b5ab1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\pandas_main\\.venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys; print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82003623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I went and saw this movie last night after being coaxed to by a few friends of mine. Ill admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater which was sold out was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge.\n",
      "['i', 'went', 'and', 'saw', 'thi', 'movi', 'last', 'night', 'after', 'be', 'coax', 'to', 'by', 'a', 'few', 'friend', 'of', 'mine.', 'ill', 'admit', 'that']\n",
      "['runners', 'like', 'runing']\n"
     ]
    }
   ],
   "source": [
    "# 문서를 토큰으로 나누기\n",
    "from nltk.stem import PorterStemmer # 딥러닝가면 많은 라이브러리가 있대..\n",
    "\n",
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "\n",
    "# 어간 추출 Stemming 단어의 접미사 -s  , -es , -ing -ed 등등을 강제로 제거해서 단어의 원형을 찾는 과정\n",
    "\n",
    "print(df.review[0])\n",
    "print(tokenizer_porter(df.review[0][:100]))\n",
    "print(tokenizer('runners like runing'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80f9f2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# | 기능                        | 설명                                 | 예시                                       |\n",
    "# | --------------------------- | ------------------------------------ | ------------------------------------------ |\n",
    "# | **Tokenization (토큰화)**   | 문장을 단어로 쪼갬                   | `\"I love dogs.\" → ['I','love','dogs','.']` |\n",
    "# | **Stopwords 제거**          | “a, the, is” 같은 불필요 단어 제거   | `\"This is a cat\" → ['cat']`                |\n",
    "# | **Stemming**                | 단어의 어근만 남김                   | `\"playing\", \"played\" → \"play\"`             |\n",
    "# | **POS tagging**             | 품사(명사, 동사 등) 붙이기           | `\"dog → 명사(NN)\"`                         |\n",
    "# | **WordNet**                 | 단어의 뜻·유의어 사전 사용 가능      | `\"happy → glad, joyful\"`                   |\n",
    "# | **감정분석, 문서요약 등**   | 텍스트 마이닝 기초로 활용            | 리뷰 긍·부정 분류 등                       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "150e1a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\playdata\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# 불용어\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')    # 불용어 사전 다운로드\n",
    "stops =  stopwords.words('english')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dca97ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  target\n",
       "0  I went and saw this movie last night after bei...       1\n",
       "1  I went and saw this movie last night after bei...       1\n",
       "2  I went and saw this movie last night after bei...       1\n",
       "3  I went and saw this movie last night after bei...       1\n",
       "4  I went and saw this movie last night after bei...       1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()  # 전처리완료  정규식을 이용한..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "337be65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\playdata\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "d:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "첫 번째 테스트 샘플: I went and saw this movie last night after being coaxed to by a few friends of mine. Ill admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater which was sold out was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge.\n",
      "첫 번째 테스트 레이블: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer         \n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')    # 불용어 사전 다운로드\n",
    "stops =  set(stopwords.words('english'))\n",
    "\n",
    "X = df.review\n",
    "y = df.target\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.2,stratify=y,random_state=42)\n",
    "\n",
    "# 어간추출(postStemmer) -> stopwor에 포함된 단어제거\n",
    "porter = PorterStemmer()\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split() if word.lower() not in stops]\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    tokenizer=tokenizer_porter,\n",
    "    ngram_range=(1,1) # (1,1) 유니그램(unigramm, 단일단어)만 사용\n",
    ")\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', tfidf),\n",
    "    ('clf', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "pipeline.fit(x_train, y_train)\n",
    "\n",
    "print(\"\\n첫 번째 테스트 샘플:\", x_test.to_numpy()[0])\n",
    "print(\"첫 번째 테스트 레이블:\", y_test.to_numpy()[0])\n",
    "\n",
    "pipeline.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13491980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본데이터로드..\n",
    "# 토크나이져 함수를 정의\n",
    "    # 텍스트 전처리\n",
    "    # 공백을 기준으로 단어단위로 분리\n",
    "    # 영어는 전부 소문자로 변환\n",
    "    # 어간 추출\n",
    "    # 불용어 제거\n",
    "# TFIDF를 정의\n",
    "    # 토크나이져 매개변수 = 토크나이져 함수\n",
    "    # ngram  (1,1)\n",
    "# 파이프라인으로 tfidf, 머신러닝\n",
    "# 파이프라이으로 학습\n",
    "# 파이프라인으로 평가( classification_report)\n",
    "# 과적합여부 확인\n",
    "\n",
    "# train 폴더에 있는데이터로 학습 - 적당한 크기로\n",
    "# test 폴더에 있는 문장으로 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "551dee19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "empty vocabulary; perhaps the documents only contain stop words",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     53\u001b[39m x = np.array([\u001b[38;5;28mstr\u001b[39m(x.item()) \u001b[38;5;28;01mfor\u001b[39;00m x,y \u001b[38;5;129;01min\u001b[39;00m train_lists])\n\u001b[32m     54\u001b[39m y = np.array([y \u001b[38;5;28;01mfor\u001b[39;00m _,y \u001b[38;5;129;01min\u001b[39;00m train_lists])\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:655\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    648\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    649\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `transform_input` parameter can only be set if metadata \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    650\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrouting is enabled. You can enable metadata routing using \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    651\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m`sklearn.set_config(enable_metadata_routing=True)`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    652\u001b[39m     )\n\u001b[32m    654\u001b[39m routed_params = \u001b[38;5;28mself\u001b[39m._check_method_params(method=\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, props=params)\n\u001b[32m--> \u001b[39m\u001b[32m655\u001b[39m Xt = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[33m\"\u001b[39m\u001b[33mPipeline\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m._log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.steps) - \u001b[32m1\u001b[39m)):\n\u001b[32m    657\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:589\u001b[39m, in \u001b[36mPipeline._fit\u001b[39m\u001b[34m(self, X, y, routed_params, raw_params)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[32m    583\u001b[39m step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    584\u001b[39m     step_idx=step_idx,\n\u001b[32m    585\u001b[39m     step_params=routed_params[name],\n\u001b[32m    586\u001b[39m     all_params=raw_params,\n\u001b[32m    587\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m X, fitted_transformer = \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    590\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    592\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    593\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    594\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPipeline\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    597\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    598\u001b[39m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[32m    599\u001b[39m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[32m    600\u001b[39m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[32m    601\u001b[39m \u001b[38;5;28mself\u001b[39m.steps[step_idx] = (name, fitted_transformer)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\joblib\\memory.py:326\u001b[39m, in \u001b[36mNotMemorizedFunc.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:1540\u001b[39m, in \u001b[36m_fit_transform_one\u001b[39m\u001b[34m(transformer, X, y, weight, message_clsname, message, params)\u001b[39m\n\u001b[32m   1538\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[32m   1539\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[33m\"\u001b[39m\u001b[33mfit_transform\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1540\u001b[39m         res = \u001b[43mtransformer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit_transform\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1541\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1542\u001b[39m         res = transformer.fit(X, y, **params.get(\u001b[33m\"\u001b[39m\u001b[33mfit\u001b[39m\u001b[33m\"\u001b[39m, {})).transform(\n\u001b[32m   1543\u001b[39m             X, **params.get(\u001b[33m\"\u001b[39m\u001b[33mtransform\u001b[39m\u001b[33m\"\u001b[39m, {})\n\u001b[32m   1544\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2105\u001b[39m, in \u001b[36mTfidfVectorizer.fit_transform\u001b[39m\u001b[34m(self, raw_documents, y)\u001b[39m\n\u001b[32m   2098\u001b[39m \u001b[38;5;28mself\u001b[39m._check_params()\n\u001b[32m   2099\u001b[39m \u001b[38;5;28mself\u001b[39m._tfidf = TfidfTransformer(\n\u001b[32m   2100\u001b[39m     norm=\u001b[38;5;28mself\u001b[39m.norm,\n\u001b[32m   2101\u001b[39m     use_idf=\u001b[38;5;28mself\u001b[39m.use_idf,\n\u001b[32m   2102\u001b[39m     smooth_idf=\u001b[38;5;28mself\u001b[39m.smooth_idf,\n\u001b[32m   2103\u001b[39m     sublinear_tf=\u001b[38;5;28mself\u001b[39m.sublinear_tf,\n\u001b[32m   2104\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2105\u001b[39m X = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2106\u001b[39m \u001b[38;5;28mself\u001b[39m._tfidf.fit(X)\n\u001b[32m   2107\u001b[39m \u001b[38;5;66;03m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[32m   2108\u001b[39m \u001b[38;5;66;03m# we set copy to False\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1377\u001b[39m, in \u001b[36mCountVectorizer.fit_transform\u001b[39m\u001b[34m(self, raw_documents, y)\u001b[39m\n\u001b[32m   1369\u001b[39m             warnings.warn(\n\u001b[32m   1370\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mUpper case characters found in\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1371\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m vocabulary while \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlowercase\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1372\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m is True. These entries will not\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1373\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33m be matched with any documents\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1374\u001b[39m             )\n\u001b[32m   1375\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1377\u001b[39m vocabulary, X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.binary:\n\u001b[32m   1380\u001b[39m     X.data.fill(\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1283\u001b[39m, in \u001b[36mCountVectorizer._count_vocab\u001b[39m\u001b[34m(self, raw_documents, fixed_vocab)\u001b[39m\n\u001b[32m   1281\u001b[39m     vocabulary = \u001b[38;5;28mdict\u001b[39m(vocabulary)\n\u001b[32m   1282\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vocabulary:\n\u001b[32m-> \u001b[39m\u001b[32m1283\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1284\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mempty vocabulary; perhaps the documents only contain stop words\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1285\u001b[39m         )\n\u001b[32m   1287\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m indptr[-\u001b[32m1\u001b[39m] > np.iinfo(np.int32).max:  \u001b[38;5;66;03m# = 2**31 - 1\u001b[39;00m\n\u001b[32m   1288\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _IS_32BIT:\n",
      "\u001b[31mValueError\u001b[39m: empty vocabulary; perhaps the documents only contain stop words"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_data(pattern, neg=True,to = None):\n",
    "    documents = []\n",
    "    if to is not None:\n",
    "        for path in tqdm(glob(pattern)[ : to]):\n",
    "            with open(path, 'r', encoding='utf-8') as f:\n",
    "                documents.append(  (np.array(f.read()),  0 if neg else 1)   )\n",
    "    else:\n",
    "        for path in tqdm(glob(pattern)):\n",
    "            with open(path, 'r', encoding='utf-8') as f:\n",
    "                documents.append(  (np.array(f.read()),  0 if neg else 1)   )\n",
    "    return documents\n",
    "\n",
    "\n",
    "train_neg_lists = get_data(\"../data/movie/train/neg/*.txt\",True,5000)\n",
    "train_pos_lists = get_data(\"../data/movie/train/pos/*.txt\",False,5000)\n",
    "test_neg_lists = get_data(\"../data/movie/test/neg/*.txt\",True,5000)\n",
    "test_pos_lists = get_data(\"../data/movie/test/pos/*.txt\",False,5000)\n",
    "# \"../data/movie/train/neg/*.txt\"  \n",
    "\n",
    "\n",
    "train_lists = train_neg_lists + train_pos_lists\n",
    "test_lists = test_neg_lists + test_pos_lists\n",
    "len(train_lists) , len(test_lists)\n",
    "\n",
    "\n",
    "import re\n",
    "porter = PorterStemmer()\n",
    "def custom_tokenizer(text):\n",
    "    # 전처리\n",
    "    # 1. 영문, 공백, ., , 만 남기기\n",
    "    clean = re.sub(r'[^A-Za-z\\s.,]+', '', text)\n",
    "    # 2. 연속된 마침표(...)를 마침표 하나로\n",
    "    clean = re.sub(r'\\.{2,}', '.', clean)\n",
    "    # 3. 연속된 공백 정리\n",
    "    clean = re.sub(r'\\s+', ' ', clean).strip()\n",
    "    # 단어분리-어간분리-불용어제거\n",
    "    return [porter.stem(word) for word in clean.split() if word not in stops]\n",
    "tfidf = TfidfVectorizer(\n",
    "    tokenizer=custom_tokenizer,\n",
    "    ngram_range=(1,1),\n",
    "    token_pattern=None\n",
    ")\n",
    "pipeline = Pipeline([\n",
    "    ('tfid',tfidf),\n",
    "    ('clf',LogisticRegression())\n",
    "])\n",
    "\n",
    "\n",
    "x = np.array([str(x.item()) for x,y in train_lists])\n",
    "y = np.array([y for _,y in train_lists])\n",
    "\n",
    "pipeline.fit(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e28d99c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "195    0\n",
       "196    0\n",
       "197    0\n",
       "198    0\n",
       "199    0\n",
       "Name: target, Length: 200, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1bee9798",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Pipeline is not fitted yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFittedError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:53\u001b[39m, in \u001b[36m_raise_or_warn_if_not_fitted\u001b[39m\u001b[34m(estimator)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:1185\u001b[39m, in \u001b[36mPipeline.score\u001b[39m\u001b[34m(self, X, y, sample_weight, **params)\u001b[39m\n\u001b[32m   1184\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter(with_final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m1185\u001b[39m     Xt = \u001b[43mtransform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1186\u001b[39m score_params = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2129\u001b[39m, in \u001b[36mTfidfVectorizer.transform\u001b[39m\u001b[34m(self, raw_documents)\u001b[39m\n\u001b[32m   2127\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m, msg=\u001b[33m\"\u001b[39m\u001b[33mThe TF-IDF vectorizer is not fitted\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2129\u001b[39m X = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tfidf.transform(X, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1419\u001b[39m, in \u001b[36mCountVectorizer.transform\u001b[39m\u001b[34m(self, raw_documents)\u001b[39m\n\u001b[32m   1416\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1417\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIterable over raw text documents expected, string object received.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1418\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1419\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_vocabulary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# use the same matrix-building strategy as fit_transform\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:501\u001b[39m, in \u001b[36m_VectorizerMixin._check_vocabulary\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    500\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fixed_vocabulary_:\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[33m\"\u001b[39m\u001b[33mVocabulary not fitted or provided\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.vocabulary_) == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mNotFittedError\u001b[39m: Vocabulary not fitted or provided",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNotFittedError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m x = np.array([\u001b[38;5;28mstr\u001b[39m(x.item()) \u001b[38;5;28;01mfor\u001b[39;00m x,y \u001b[38;5;129;01min\u001b[39;00m train_lists])\n\u001b[32m      2\u001b[39m y = np.array([y \u001b[38;5;28;01mfor\u001b[39;00m _,y \u001b[38;5;129;01min\u001b[39;00m train_lists])\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:1181\u001b[39m, in \u001b[36mPipeline.score\u001b[39m\u001b[34m(self, X, y, sample_weight, **params)\u001b[39m\n\u001b[32m   1145\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Transform the data, and apply `score` with the final estimator.\u001b[39;00m\n\u001b[32m   1146\u001b[39m \n\u001b[32m   1147\u001b[39m \u001b[33;03mCall `transform` of each transformer in the pipeline. The transformed\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1178\u001b[39m \u001b[33;03m    Result of calling `score` on the final estimator.\u001b[39;00m\n\u001b[32m   1179\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1180\u001b[39m \u001b[38;5;66;03m# TODO(1.8): Remove the context manager and use check_is_fitted(self)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _raise_or_warn_if_not_fitted(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1182\u001b[39m     Xt = X\n\u001b[32m   1183\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py:162\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    160\u001b[39m     value = typ()\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:55\u001b[39m, in \u001b[36m_raise_or_warn_if_not_fitted\u001b[39m\u001b[34m(estimator)\u001b[39m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[33m\"\u001b[39m\u001b[33mPipeline is not fitted yet.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# we only get here if the above didn't raise\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mNotFittedError\u001b[39m: Pipeline is not fitted yet."
     ]
    }
   ],
   "source": [
    "x = np.array([str(x.item()) for x,y in train_lists])\n",
    "y = np.array([y for _,y in train_lists])\n",
    "pipeline.score(x_test , y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "563658a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Pipeline is not fitted yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFittedError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:53\u001b[39m, in \u001b[36m_raise_or_warn_if_not_fitted\u001b[39m\u001b[34m(estimator)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:788\u001b[39m, in \u001b[36mPipeline.predict\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter(with_final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m788\u001b[39m     Xt = \u001b[43mtransform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m1\u001b[39m].predict(Xt, **params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2129\u001b[39m, in \u001b[36mTfidfVectorizer.transform\u001b[39m\u001b[34m(self, raw_documents)\u001b[39m\n\u001b[32m   2127\u001b[39m check_is_fitted(\u001b[38;5;28mself\u001b[39m, msg=\u001b[33m\"\u001b[39m\u001b[33mThe TF-IDF vectorizer is not fitted\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2129\u001b[39m X = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tfidf.transform(X, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1419\u001b[39m, in \u001b[36mCountVectorizer.transform\u001b[39m\u001b[34m(self, raw_documents)\u001b[39m\n\u001b[32m   1416\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1417\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mIterable over raw text documents expected, string object received.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1418\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1419\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_vocabulary\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1421\u001b[39m \u001b[38;5;66;03m# use the same matrix-building strategy as fit_transform\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:501\u001b[39m, in \u001b[36m_VectorizerMixin._check_vocabulary\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    500\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fixed_vocabulary_:\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[33m\"\u001b[39m\u001b[33mVocabulary not fitted or provided\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    503\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.vocabulary_) == \u001b[32m0\u001b[39m:\n",
      "\u001b[31mNotFittedError\u001b[39m: Vocabulary not fitted or provided",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mNotFittedError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m classification_report\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m classification_report(y_test, \u001b[43mpipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:783\u001b[39m, in \u001b[36mPipeline.predict\u001b[39m\u001b[34m(self, X, **params)\u001b[39m\n\u001b[32m    741\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Transform the data, and apply `predict` with the final estimator.\u001b[39;00m\n\u001b[32m    742\u001b[39m \n\u001b[32m    743\u001b[39m \u001b[33;03mCall `transform` of each transformer in the pipeline. The transformed\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    780\u001b[39m \u001b[33;03m    Result of calling `predict` on the final estimator.\u001b[39;00m\n\u001b[32m    781\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    782\u001b[39m \u001b[38;5;66;03m# TODO(1.8): Remove the context manager and use check_is_fitted(self)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m783\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _raise_or_warn_if_not_fitted(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    784\u001b[39m     Xt = X\n\u001b[32m    786\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\contextlib.py:162\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    160\u001b[39m     value = typ()\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\pandas_main\\.venv\\Lib\\site-packages\\sklearn\\pipeline.py:55\u001b[39m, in \u001b[36m_raise_or_warn_if_not_fitted\u001b[39m\u001b[34m(estimator)\u001b[39m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m NotFittedError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(\u001b[33m\"\u001b[39m\u001b[33mPipeline is not fitted yet.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# we only get here if the above didn't raise\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mNotFittedError\u001b[39m: Pipeline is not fitted yet."
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "classification_report(y_test, pipeline.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a990e3f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
