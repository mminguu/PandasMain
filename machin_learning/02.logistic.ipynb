{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a35d724c",
   "metadata": {},
   "source": [
    "#### logistic 합격 불합격을 판단\n",
    "```\n",
    "공부한 시간 데이터를 보고 합격여부를 예측\n",
    "공부시간에 비례해서 점수를 부여\n",
    "공부 1시간에 10점 부여\n",
    "--> 선형 방정식  :  z(합격점수) = w(가중치)* 공부시간 + b(편향)\n",
    "w(가중치) : 중요도 1시간당 점수 ( 10점 )\n",
    "b(편향) : 기본점수 ( -50 , 5시간은 공부해야 0점 )\n",
    "\n",
    "문제점 : 합격점수에 해당하는 100점이 나올수도 있지만 -200점이 나올수도 있음..\n",
    "분류를 하려면 즉, 합격 불합격판단... 우리가 원하는 것은 방정식의 값으로 확률을 계산하고 싶음. (확률은 0 ~ 100)\n",
    "```\n",
    "\n",
    "#### 점수를 확률로 바꿔야한다(시그모이드 함수를 이용)\n",
    "```\n",
    "0 ~ 1 사이의 확률값으로 변경해줌\n",
    "합격확률 - 시그모이드(z) = 1 / 1 + e^ - z\n",
    "1 : 합격점수 높음\n",
    "0 : 합격점수 낮음\n",
    "합격점수가 0이면 정확히 0.5(50%) - 임계값(임계치)\n",
    "```\n",
    "\n",
    "#### 비용함수 : 모델이 얼마나 틀렸는지 측정  /  로지스틱은 로그함수를 사용\n",
    "```\n",
    "합격을 예측했다 (정답=1)\n",
    "모델이 99%로 합격 예측했다? -> 벌점은 거의 0점\n",
    "모델이 1%로 합격 예측했다? -> 벌점은 무한대로 크게\n",
    "\n",
    "불합격을 예측했다 (정답=0)\n",
    "모델이 1%로 합격 예측했다? -> 벌점은 거의 0점\n",
    "모델이 99%로 합격 예측했다? -> 벌점은 무한대로 크게\n",
    "\n",
    "log loss 원리\n",
    "w,b 를 찾음.. 손실함수를 이용해서 비용이 가장 낮을때\n",
    "\n",
    "```\n",
    "\n",
    "#### 비용이 최저인 값을 찾아나가는 과정 : 경사하강법\n",
    "\n",
    "#### 학습에 대해 너무 완벽한 모델\n",
    "```\n",
    "규제(Regularization) 모델이 너무 복잡해 지지않도록 패널티 또는 단순함에 대한 보너스\n",
    "L2규제(Ridge) : w(중요도) 값이 너무 커지는 것을 막는다. 가중치(w) 제곱의 합을 벌점으로 추가\n",
    "L1규제(Lasso) : 어떤 특징이 별로 안 중요할거 같은 특징이 있음 그냥 w(중요도)를 그냥 0으로 만든다. / 불필요한 특성을 제거하는 효과 / 가중치들(w)의 절대값의 합을 패널티로 추가\n",
    "- feature selector 역할도 함\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1368a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0] [1 1 1 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.46356522e-01, 6.53643478e-01],\n",
       "       [1.24501128e-02, 9.87549887e-01],\n",
       "       [6.54332975e-03, 9.93456670e-01],\n",
       "       [4.63391140e-01, 5.36608860e-01],\n",
       "       [9.99894002e-01, 1.05998413e-04]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "x_train, x_test , y_train , y_test = train_test_split(X , y , test_size=0.3 , stratify=y)\n",
    "\n",
    "clr = LogisticRegression(max_iter=10000)\n",
    "clr.fit(x_train , y_train)\n",
    "predict = clr.predict(x_test)\n",
    "print(predict[:5] , y_test[:5])\n",
    "predict_proba = clr.predict_proba(x_test)\n",
    "predict_proba[:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81ec1533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 시각화 함수 (공통) ---\n",
    "def plot_decision_boundary(model, X_orig, y_orig, poly_transformer, scaler_transformer, title, subplot_ax):\n",
    "    \"\"\"모델의 결정 경계를 그려주는 함수\"\"\"\n",
    "    # 1. 그래프를 그릴 영역을 정의합니다.\n",
    "    x_min, x_max = X_orig[:, 0].min() - 0.5, X_orig[:, 0].max() + 0.5\n",
    "    y_min, y_max = X_orig[:, 1].min() - 0.5, X_orig[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.02),\n",
    "                         np.arange(y_min, y_max, 0.02))\n",
    "\n",
    "    # 2. 그래프 영역의 모든 점들을 모델이 예측할 수 있도록 변환합니다.\n",
    "    grid_poly = poly_transformer.transform(np.c_[xx.ravel(), yy.ravel()])\n",
    "    grid_scaled = scaler_transformer.transform(grid_poly)\n",
    "\n",
    "    # 3. 변환된 점들을 모델로 예측합니다.\n",
    "    Z = model.predict(grid_scaled)\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    # 4. 결정 경계와 원본 데이터 포인트를 그립니다.\n",
    "    subplot_ax.contourf(xx, yy, Z, alpha=0.3, cmap=plt.cm.coolwarm)\n",
    "    subplot_ax.scatter(X_orig[:, 0], X_orig[:, 1], c=y_orig, cmap=plt.cm.coolwarm, edgecolors='k')\n",
    "    subplot_ax.set_title(title)\n",
    "    subplot_ax.set_xlabel(\"Feature 1\")\n",
    "    subplot_ax.set_ylabel(\"Feature 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41a297aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과적합을 임의로 만들어서 시각화\n",
    "# 1. 규제 알고리즘을 적용\n",
    "# 2. 모델을 경량화.. 모델의 복잡도를 높이는 요소를 제거\n",
    "# 3. 추가 데이터를 투입해서 학습\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18fbd1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def plot_decision_boundary(model, X, y, poly, scaler, title, ax):\n",
    "    # 과적합이 심해도 데이터를 추가하면 완만해지는 효과가 있음.\n",
    "    fig , axes = plt.subplots(1,3,figsize=(20,6))\n",
    "    # 과적합 모델\n",
    "    X_small , y_small = make_moons(n_samples=50 , noise=0.25 , random_state=45)\n",
    "\n",
    "\n",
    "    # 고차항 특성으로 변환을 할껀데 과적합을 유도할꺼임\n",
    "    poly = PolynomialFeatures(degree=10 , include_bias=False)\n",
    "    X_poly_small = poly.fit_transform(X_small)\n",
    "\n",
    "    # 데이터 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled_small = scaler.fit_transform(X_poly_small)\n",
    "\n",
    "    # 모델훈련\n",
    "    log_reg_overfit = LogisticRegression(C=1000,max_iter=10000) # C가 규제강도. 클수록 규제를 약하게  max_iter는 학습횟수\n",
    "    log_reg_overfit.fit(X_scaled_small , y_small)\n",
    "    plot_decision_boundary(log_reg_overfit , X_small , y_small , poly , scaler , 'overfitting model data=50',axes[0])# 학습에 너무 치중한 결과\n",
    "\n",
    "    # 규제 적용 (데이터 50개 , 강한 규제 적용해보자) - 과적합 예상됨\n",
    "    log_reg_regulation = LogisticRegression(C=0.1,max_iter=10000)\n",
    "    log_reg_regulation.fit(X_scaled_small , y_small)\n",
    "    plot_decision_boundary(log_reg_regulation , X_small , y_small , poly , scaler , 'C=0.1 max_iter=1000 data=50',axes[1])\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "    # 데이터를 추가 ( 데이터 500추가 , 약하게)\n",
    "    X_large , y_large = make_moons(n_samples=500 , noise=0.25 , random_state=45) # noise는 값을 일부러 흐트러뜨림 (숫자가 높을수록 과적합up)\n",
    "\n",
    "    # 고차항 특성으로 변환을 할껀데 과적합을 유도할꺼임\n",
    "    poly = PolynomialFeatures(degree=10 , include_bias=False)\n",
    "    X_poly_large = poly.fit_transform(X_large)\n",
    "\n",
    "    # 데이터 스케일링\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled_large = scaler.fit_transform(X_poly_large)\n",
    "\n",
    "    # 모델훈련(데이터 500개 , 약한 규제)\n",
    "    log_reg_moredata = LogisticRegression(C=1000,max_iter=10000,random_state=45) # C가 규제강도. 클수록 규제를 약하게  max_iter는 학습횟수\n",
    "    log_reg_moredata.fit(X_scaled_large , y_large)\n",
    "    plot_decision_boundary(log_reg_moredata , X_large , y_large , poly , scaler , 'C=1000 max_iter=1000 data=500',axes[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9094a2e",
   "metadata": {},
   "source": [
    "#### ROC , AUC\n",
    "```\n",
    "정확도 99% but, 데이터가 불균형이라면 좋은 척도가 못된다..\n",
    "ROC AUC 가 얼마나 안정적으로 ㅈ호은 성능을 내는지를 종합적으로 시각화\n",
    "모델이 예측한 확률을 기반으로 분류기준점(The=reshold)을 계속 변경해서 모델의 성능이 어떻게 변하는지 하나의 곡선으로 알 수 있다.\n",
    "```\n",
    "\n",
    "#### ROC 구성요소 TPR FPR\n",
    "```\n",
    "* 암을 예시로 들어보면,\n",
    "\n",
    "혼동행렬 (P : 1 , N : 0) P : 암환자, N : 정상\n",
    "TP(True Positive) : 진짜 암환자라고 예측 (정답) *중요\n",
    "FN(False Negative) : 진짜 암환자를 정상으로 예측 (오답) / 놓친 암환자 *중요\n",
    "FP(False Positive) : 정상인 사람을 암환자라고 예측 (오답)\n",
    "TN(True Negative) : 정상인 사람을 정상이라고 예측 (정답)\n",
    "    뒤에 있는게 예측한거고 앞에 있는게 맞다 틀리다로 보면 됨 \n",
    "ROC 곡선의 x와 y축\n",
    "y축 : 진짜를 얼마나 잘 찾았냐  TPR(True Positive Rate) 실제 양성인 데이터 중 모델이 양성으로 올바르게 예측한 비율\n",
    "실제 암환자인데 암환자라고 예측 / 실제 모든 암 환자 수 = TP / TP + FN = TPR\n",
    "\n",
    "x축 : 가짜를 얼마나 잘못 찾았냐  FPR(False Positive Rate) 실제 음성인 데이터 중 모델이 양성으로 잘못 예측한 비율\n",
    "정상인데 암이라고 예측 / 실제 모든 정상인 수 = FP / FP + TN = FPR\n",
    "```\n",
    "\n",
    "#### AUC (Area Under The Curve)\n",
    "```\n",
    "ROC 곡선 아래의 면적\n",
    "1 : 완벽한 모델 ROC가 좌측상단에 붙어 있는 모양\n",
    "0.5 : 무작위로 찍는것과 같은 즉, 랜덤하게 예측하는 수준 ROC 대각선 직선\n",
    "< 0.5 : 예측을 반대로 즉, 잘못된 모델\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc59ad60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAKcNJREFUeJzt3Ql0VOX5x/EHAtmUBBQJWwRFURABJZIDiIonmhYL2qogWDYVRdEqqQsIggISRUWsBqgoQlsR0CJaQaigqEiUEqS1IlBkCSKJ8JdNtkBy/+d5PTMmYSbJJDPzzvL9nHNJ7s29M+/chLm/ebdby3EcRwAAACypbeuJAQAAFGEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFV1JAyUlJTI999/L/Xq1ZNatWrZLg4AAKgCnVf10KFD0rRpU6ldu3Z4hxENIqmpqbaLAQAAqmHnzp3SvHnz8A4jWiPiejFJSUm2iwMAAKrg4MGDpjLBdR0P6zDiaprRIEIYAQAgvFTWxYIOrAAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAACC8wsgnn3wivXr1Mje90RnVFi1aVOkxK1eulEsvvVTi4uLkvPPOk9mzZ1e3vAAAINrDyOHDh6VDhw6Sk5NTpf23bdsm1113nfTo0UPWr18vDzzwgNxxxx2ybNmy6pQXAABEGJ/vTfPrX//aLFU1Y8YMOeecc+S5554z623atJFVq1bJ888/L5mZmb4+PQCExG3Rj54otl0MwK8S6sZUeg+ZQAn4jfJyc3MlIyOjzDYNIVpD4s3x48fNUvqufwAQKkHkphm5krdjn+2iAH61YXymJMbWicwOrAUFBZKSklJmm65rwDh69KjHY7KzsyU5Odm96O2HASAUaI0IQQTwLzsRqBKjRo2SrKws97oGFwIJgFCzdkyGJMbG2C4G4LdmmogNI40bN5bCwsIy23Q9KSlJEhISPB6jo250ARBZIqGvxZGiX8qvQcRWtTYQSQL+v6hLly6yZMmSMts++OADsx1A9KCvBQC/9Rn56aefzBBdXVxDd/X7/Px8dxPLwIED3fsPGzZMtm7dKg8//LBs3LhRpk2bJgsWLJARI0b4+tQAwlik9bVIa9HAarU2ENU1I2vXrjVzhri4+nYMGjTITGa2e/dudzBROqx38eLFJny88MIL0rx5c3nllVcY1gtEWZNL6eaNSOhrYXMYJBBpajn6jhLitAOrjqo5cOCA6WsCILybXGwOIQQQetdv7k0DIKhNLjRvACiPjyYAasTXJheaNwCURxgBwpTNYbIMbwXgT7yDAGGIYbIAIgl9RoAwFCrDZOn/AcAfqBkBwrBZJlSGydL/A4A/EEaAMG+Woc8GgHBHMw0Qxs0yNJMAiAR8nALCYBSMt2YZmkkARALCCBBmo2BolgEQaWimAcJoFAzNMgAiER+vAEuqMwqGZhkAkYgwAlgakktzCwD8jHdCIICYKRUAKkefESCAGJILAJWjZgSoIobkAkBgEEaAKmBILgAEDs00QBUwJBcAAoePaUAQbkxHswwAeEcYATzgxnQAEDw00wAeMAoGAIKHj3dAJRgFAwCBRRgBKkGzDAAEFs00AADAKsIIAACwirpnwMPsqqWH8gIAAoswgqjHzewAwC6aaRD1KppdlaG8ABB41IwgKlV1dlWG8gJA4BFGEHWYXRUAQgvNNIg6zK4KAKGFj4CIasyuCgD2EUYQ1WiWAQD7aKYBAABWEUYAAIBV1E8j4jG7KgCENsIIIhqzqwJA6KOZBhGN2VUBIPRRM4KoweyqABCaCCMIm74e1VG6fwjDeAEgNPHOjJBEXw8AiB70GUHY9fWoDvqHAEDoomYEIT/8tnxfj+qgfwgAhC7CCEK+SYa+HgAQ2WimgXUMvwWA6MbHTYQUht8CQPQhjCCk0CQDANGHZhoAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBXDFmB9xtXSs60CAKIPYQRBx03wAACl0UyDkJlxldlWASA6UTOCkLkJHrOtAkB0IowgoLgJHgAgIM00OTk50rJlS4mPj5f09HRZs2ZNhftPnTpVLrjgAklISJDU1FQZMWKEHDt2rDpPjTDDTfAAAJXx+SPp/PnzJSsrS2bMmGGCiAaNzMxM2bRpkzRq1OiU/efOnSsjR46UWbNmSdeuXWXz5s0yePBgUx0/ZcoUX58eYYyb4AEA/FIzogFi6NChMmTIEGnbtq0JJYmJiSZseLJ69Wrp1q2b9O/f39SmXHvttdKvX79Ka1MQeVxNMq6FIAIA8DmMFBUVSV5enmRkZLi31a5d26zn5uZ6PEZrQ/QYV/jYunWrLFmyRHr27On1eY4fPy4HDx4sswAAgMjkUzPN3r17pbi4WFJSUsps1/WNGzd6PEZrRPS4yy+/3HRmPHnypAwbNkweffRRr8+TnZ0tTzzxhC9FAwAAYSrg84ysXLlSJk2aJNOmTZN169bJwoULZfHixTJhwgSvx4waNUoOHDjgXnbu3BnoYgIAgHCoGWnYsKHExMRIYWFhme263rhxY4/HPPbYYzJgwAC54447zPrFF18shw8fljvvvFNGjx5tmnnKi4uLMwsAAIh8PtWMxMbGSqdOnWTFihXubSUlJWa9S5cuHo85cuTIKYFDA43SZhsAABDdfB7aq8N6Bw0aJGlpadK5c2cztFdrOnR0jRo4cKA0a9bM9PtQvXr1MiNwLrnkEjMUeMuWLaa2RLe7QgkAAIhePoeRvn37yp49e2Ts2LFSUFAgHTt2lKVLl7o7tebn55epCRkzZowZwqlfd+3aJWeddZYJIk8++aR/XwkAAAhLtZwwaCvRob3JycmmM2tSUpLt4sAHR4pOStuxy8z3G8ZnMvU7AESRg1W8fnPXXgAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWMekD/E6nrjl6oth8f6To568AAHhDGIHfg8hNM3Ilb8c+20UBAIQJmmngV1oj4imIpLVoIAl1uRcRAOBU1IwgYNaOyZDE2J8DiAYRvUcRAADlEUYQMBpEuBcNAKAyNNMAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAq5geE367Q6/iLr0AAF8RRlBt3KEXAOAPNNPA73foVdylFwBQVdSMwO936FXcpRcAUFWEEfgFd+gFAFQXzTQAAMAqwggAALCKenVUeygvw3gBAP5AGEGVMZQXABAINNOgxkN5GcYLAKgJakZQ46G8DOMFANQEYQTVwlBeAIC/0EwDAACs4qMtvOImeACAYCCMwCNGzgAAgoVmGnjETfAAAMFCzQgqxU3wAACBRBhBpbOrMnIGABBIXGFg0EcEAGALfUZgMLsqAMAWakaiVEXDdpldFQAQTISRKFRZkwx9RAAAwUQzTRRi2C4AIJTw8TfKMWwXAGAbYSTK0SQDALCNZhoAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFVNvRuFdekvfoRcAgLCsGcnJyZGWLVtKfHy8pKeny5o1ayrcf//+/TJ8+HBp0qSJxMXFSevWrWXJkiXVLTOqeZfetmOXmSVt4nLbRQIAoPo1I/Pnz5esrCyZMWOGCSJTp06VzMxM2bRpkzRq1OiU/YuKiuSaa64xP3vrrbekWbNmsmPHDqlfv76vTw0/36WXO/QCAMIyjEyZMkWGDh0qQ4YMMesaShYvXiyzZs2SkSNHnrK/bv/xxx9l9erVUrduXbNNa1Vg/y693KEXABB2zTRay5GXlycZGRm/PEDt2mY9NzfX4zHvvvuudOnSxTTTpKSkSLt27WTSpElSXOy938Lx48fl4MGDZRb49y69uhBEAABhF0b27t1rQoSGitJ0vaCgwOMxW7duNc0zepz2E3nsscfkueeek4kTJ3p9nuzsbElOTnYvqampvhQTAACEkYAP7S0pKTH9RV5++WXp1KmT9O3bV0aPHm2ad7wZNWqUHDhwwL3s3Lkz0MUEAADh0GekYcOGEhMTI4WFhWW263rjxo09HqMjaLSviB7n0qZNG1OTos0+sbGxpxyjI250AQAAkc+nmhENDlq7sWLFijI1H7qu/UI86datm2zZssXs57J582YTUjwFEQAAEF18bqbRYb0zZ86UOXPmyDfffCN33323HD582D26ZuDAgaaZxUV/rqNp7r//fhNCdOSNdmDVDq0AAAA+D+3VPh979uyRsWPHmqaWjh07ytKlS92dWvPz880IGxftfLps2TIZMWKEtG/f3swzosHkkUce8e8rAQAAYamWo9Nzhjgd2qujarQza1JSku3ihJ0jRSfNzKtqw/hMM6wXAIBQuX5zozwAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVtWx+/QIBMdx5OiJYvf6kaJfvgcAINQQRiIwiNw0I1fyduyzXRQAAKqEZpoIozUi3oJIWosGklA3JuhlAgCgItSMRLC1YzIkMfaX8KFBpFatWlbLBABAeYSRCKZBJDGWXzEAILTRTAMAAKwijAAAAKuow4+wobwM4wUAhBvCSJhjKC8AINzRTBOhQ3kZxgsACBfUjEToUF6G8QIAwgVhJIIwlBcAEI5opgEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFjFXdXCjOM4cvREsXv9SNEv3wMAEDU1Izk5OdKyZUuJj4+X9PR0WbNmTZWOmzdvnrmt/Q033FCdp416GkRumpErbccucy9pE5fbLhYAAMENI/Pnz5esrCwZN26crFu3Tjp06CCZmZnyww8/VHjc9u3b5cEHH5Tu3bvXpLxRTWtE8nbs8/iztBYNJKFuTNDLBABATdVy9OO2D7Qm5LLLLpOXXnrJrJeUlEhqaqrcd999MnLkSI/HFBcXyxVXXCG33XabfPrpp7J//35ZtGhRlZ/z4MGDkpycLAcOHJCkpCSJVkeKTpraELV2TIYkxv4SPjSIaK0TAAChoqrXb59qRoqKiiQvL08yMjJ+eYDatc16bm6u1+PGjx8vjRo1kttvv71Kz3P8+HHzAkovKEuDSGJsHfdCEAEAhCufwsjevXtNLUdKSkqZ7bpeUFDg8ZhVq1bJq6++KjNnzqzy82RnZ5sk5Vq05gUAAESmgA7tPXTokAwYMMAEkYYNG1b5uFGjRpkqHdeyc+dOiVbaiqbNMz8vjJwBAET50F4NFDExMVJYWFhmu643btz4lP2//fZb03G1V69e7m3ax8Q8cZ06smnTJmnVqtUpx8XFxZkl2rlGz3jrtAoAQNTVjMTGxkqnTp1kxYoVZcKFrnfp0uWU/S+88EL56quvZP369e6ld+/e0qNHD/M9zS/VGz3DyBkAQFRPeqbDegcNGiRpaWnSuXNnmTp1qhw+fFiGDBlifj5w4EBp1qyZ6feh85C0a9euzPH169c3X8tvR8VKj55h5AwAIKrDSN++fWXPnj0yduxY02m1Y8eOsnTpUnen1vz8fDPCBoEZPQMAgET7PCM2ROs8I6XnFdkwPpMwAgAIKwGZZwQAAMDf+KgdQrgJHgAgGhFGQgTDeAEA0YpmmhDBTfAAANGKmpEQxE3wAADRhDASghjGCwCIJjTTAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCqjt2njx6O48jRE8Vef36kyPvPAACIZISRIAWRm2bkSt6OfbaLAgBAyKGZJgi0RqSqQSStRQNJqBsT8DIBABAqqBkJsrVjMiQx1nvY0CBSq1atoJYJAACbCCNBpkEkMZbTDgCAC800AADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAAAIvzCSk5MjLVu2lPj4eElPT5c1a9Z43XfmzJnSvXt3adCggVkyMjIq3B8AAEQXn8PI/PnzJSsrS8aNGyfr1q2TDh06SGZmpvzwww8e91+5cqX069dPPvroI8nNzZXU1FS59tprZdeuXf4oPwAACHO1HMdxfDlAa0Iuu+wyeemll8x6SUmJCRj33XefjBw5stLji4uLTQ2JHj9w4MAqPefBgwclOTlZDhw4IElJSRIO9LQePVFsvj9SVCxpE5eb7zeMz5TE2DqWSwcAQOBV9frt01WxqKhI8vLyZNSoUe5ttWvXNk0vWutRFUeOHJETJ07IGWec4XWf48ePm6X0iwknGkRumpEreTv22S4KAACR1Uyzd+9eU7ORkpJSZruuFxQUVOkxHnnkEWnatKkJMN5kZ2ebJOVatOYlnGiNiKcgktaigSTUjbFSJgAAQlVQ2wueeuopmTdvnulHop1fvdGaF+2XUrpmJNwCicvaMRmSGPtzANEgUqtWLdtFAgAgfMNIw4YNJSYmRgoLC8ts1/XGjRtXeOyzzz5rwsjy5culffv2Fe4bFxdnlkigQYQ+IgAA+KmZJjY2Vjp16iQrVqxwb9MOrLrepUsXr8dNnjxZJkyYIEuXLpW0tDRfnhIAAEQ4nz+ya/PJoEGDTKjo3LmzTJ06VQ4fPixDhgwxP9cRMs2aNTP9PtTTTz8tY8eOlblz55q5SVx9S04//XSzAACA6OZzGOnbt6/s2bPHBAwNFh07djQ1Hq5Orfn5+WaEjcv06dPNKJybbrqpzOPoPCWPP/64P14DAACIpnlGbAi3eUaOFJ2UtmOXme+ZVwQAEK0OVvH6zb1pAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVDPOo4R15PdG79AIAgKohjPiIO/ICAOBfNNP46Y68nnCXXgAAKkfNiJ/uyOsJd+kFAKByhJEa4I68AADUHM00AADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsKqO3acPfY7jyNETxe71I0W/fA8AAGqOMFJJELlpRq7k7dhnuygAAEQsmmkqoDUi3oJIWosGklA3JuhlAgAg0lAzUkGzTOkmmbVjMiQx9pfwoUGkVq1aVsoIAEAkIYxUsVlGg0hiLKcLAAB/o5mmCs0yNMkAABA4Uf1Rv6KRMqWbZWiSAQAgcKI2jFQ2UoZmGQAAgiNqm2kYKQMAQGjgoz8jZQAAsIowQpMMAABWRW0zDQAACA1UBwCIWsXFxXLixAnbxQDCVt26dSUmpuZ9LAkjAKJyNF1BQYHs37/fdlGAsFe/fn1p3LhxjfpaEkYARB1XEGnUqJEkJibSYR2oZqg/cuSI/PDDD2a9SZMmUl2EEQBR1zTjCiJnnnmm7eIAYS0hIcF81UCi/6eq22RDB1YAUcXVR0RrRADUnOv/Uk36XxFGAEQlmmaA0Pm/RBgBAABWEUYAAIBVhBEACAODBw821eG66NwO55xzjjz88MNy7NixU/Z977335Morr5R69eqZ9vzLLrtMZs+e7fFx//73v8tVV10lycnJcvrpp0v79u1l/Pjx8uOPPwbhVaEm3nzzTbnwwgslPj5eLr74YlmyZEmlx7z++uvSoUMH83eho19uu+02+b//+78y+2gH7+HDh5ufx8XFSevWrav02DVBGAGAMPGrX/1Kdu/eLVu3bpXnn39e/vznP8u4cePK7PPiiy/K9ddfL926dZMvvvhC/vOf/8gtt9wiw4YNkwcffLDMvqNHj5a+ffuasPL+++/Lf//7X3nuuefk3//+t/z1r38N2usqKiqSUBSq5VKrV6+Wfv36ye233y5ffvml3HDDDWbR36E3n332mQwcONAc8/XXX5sws2bNGhk6dGiZ13zNNdfI9u3b5a233pJNmzbJzJkzpVmzZhJQThg4cOCAo0XVr/5y+PgJp8Uj75lFvwcQHY4ePeps2LDBfA0ngwYNcq6//voy2373u985l1xyiXs9Pz/fqVu3rpOVlXXK8X/605/M++jnn39u1r/44guzPnXqVI/Pt2/fPq9l2blzp3PLLbc4DRo0cBITE51OnTq5H9dTOe+//37nyiuvdK/r98OHDzfbzzzzTOeqq65y+vXr5/Tp06fMcUVFRebnc+bMMevFxcXOpEmTnJYtWzrx8fFO+/btnTfffNOpipMnTzq33Xab+9jWrVuf8tpdZZ84caLTpEkTs6/rvN58881OcnKyec29e/d2tm3b5j5uzZo1TkZGhilrUlKSc8UVVzh5eXlOIPXp08e57rrrymxLT0937rrrLq/HPPPMM8655557yt9Fs2bN3OvTp083++i598f/qapev6kZARDVzMRNRSetLPrc1aWfgPXTcWxsrHubfpLV4ZXla0DUXXfdZZph3njjDXd1va7fc889XmfV9OSnn34yTUC7du2Sd99919SiaHNRSUmJT+WfM2eOKbt+Wp8xY4bceuut8o9//MM8vsuyZcvMpFq//e1vzXp2drb85S9/MfvrJ/sRI0bI73//e/n4448rfT4tX/PmzU1twIYNG2Ts2LHy6KOPyoIFC8rst2LFClMb8MEHH5jmLj2fmZmZpsnr008/NeXV86a1VK6ak0OHDsmgQYNk1apV8vnnn8v5558vPXv2NNu9cZ3/ipZPP/3U6/G5ubmSkZFRZpuWU7d706VLF9m5c6dpctG/vcLCQvM3o2V10d+p7qfNNCkpKdKuXTuZNGmSmZ8nkKo16VlOTo4888wzZhZDbXvSasHOnTt73V9/+Y899pip9tFf0tNPP13mxQOALUdPFEvbscusPPeG8Zk+3TFcL456kTp58qQcP35cateuLS+99JL755s3bzZ9PzzNhKkX/nPPPdfso/73v/+Zde1/4ou5c+fKnj175F//+pecccYZZtt5550nvtJrweTJk93rrVq1ktNOO03efvttGTBggPu5evfubYKAvl69KC5fvtxcLJWWXwOANldpQKqIvs4nnnjCva59bvTCrWGkT58+7u1ahldeecUd8v72t7+ZIKPbXENYX3vtNRPWVq5cKddee61cffXVZZ7r5ZdfNj/XkPSb3/zGY3n0daWnp1dY5mYVNI3o9VfDQmm6rtu90aY7DUHaNKd9jfTvqFevXuaa7qJNgB9++KEJhxpatmzZYgKrhrLyTYJWw8j8+fMlKyvLJFM9kVOnTjVpTJOkzr7mrV1LE63+UvSPS9u11q1bZxIXAKBqevToIdOnT5fDhw+bPiN16tSRG2+8sVqPVd1amfXr18sll1ziDiLV1alTpzLr+lo0FOjFUsOIvsZ33nlH5s2bZ36uF0WtJdH+DKVp7YSWpyr0ojtr1izJz8+Xo0ePmmM7duxYZh/tCFq6tklrfvS5NRCVphfzb7/91nyvNQxjxowx4URnItVaBC2rPo83+njlHzPQtEbo/vvvN7VCet3W/kcPPfSQ6U/06quvmn00eOm1XAOVzqaqvyetBdMKiJAKI1OmTDGdXYYMGWLWNZQsXrzY/IJHjhx5yv4vvPCCqc7SF6wmTJhgqr80zeuxAGBTQt0YU0Nh67l9oZ/aXbUQ+p6rNdN6EdEOiUpHPRw4cEC+//57adq0aZlj9cKrF08NNK59tVZBP/H6Ujvimv7bG62tKR90PM3Mqa+lPP00rjUcekHX64Q+l14/lKv5Rq835WsMdMRHZTTUaPOVdtDVmhUNAnqB1U6+FZVLn1cvyBqSyjvrrLPMV22i0REper1r0aKFKY8+R0UdYPXxtOmsIu+//750797d48/0xnQagkrTdd3ujVYKaO2I63qsI6f09epzTJw40dSo6VL+Trxt2rQxNS76ekoHNX/yqc+IFiQvL69MO5X+4em6t3aq6rRraXXcwYMHyywAEAha9a5NJTaWmsxcqe+92udBP5Hrp3yltSR6IdELbnn64U9rG7SmWvXv399caKdNm+bx8b3d0VgvYFo74m3or16g9RN3abp/VXTt2lVSU1NNDbxerG+++WZ3UGrbtq25yGttgway0oseUxnt66GPr00OWpOix7lqNipy6aWXmiYtrS0o/7zaJOZ67D/84Q+m+8FFF11kyrl3794KH1ebafS8VLSkpaV5PV7DjvZvKU0DnKsJyxOtrdG/m9JcocMVIDWsaE1Q6T5A2rSnISVQQcTnMKInV6uffGmnqk67lqY3/SW7lqr8oQFAtNGLtV5MXG3+Z599tumHoc3nOmx348aN5oKrNdrayfSPf/yju5+CfnVt06/6AXHHjh3mAqePqx1MPdEwo5++tbldL8Lax0DnKnF9wNT+E2vXrjUdTfUirlX7FQ03LU9DkgYnvbBqTYmL1mRozYZ2WtWy6evS5n7ts+itrOX7qGi5tFOsXly1H6P2e6mMlqFhw4ZmuLR2KN22bZtpjtHw8d1337kfW4dCf/PNN6amRY+prAZJX0/5cHNeuaWix9DmlqVLl5rgqb/nxx9/3Ly+e++9173PqFGjzFBeF+0fsnDhQtPUp783V4jSPp+umrS7777bBE19fD1PWhOlfXW0Q2tAVXnsjuM4u3btMkN0Vq9eXWb7Qw895HTu3NnjMTrMbO7cuWW25eTkOI0aNfL6PMeOHTPDgFyLDiPz99DekpISM6RXF/0eQHSIpKG9Kjs72znrrLOcn376yb3tnXfecbp37+6cdtppZhirDr2dNWuWx8edP3++GYpar149s78Olx0/fnyFQ3u3b9/u3HjjjWYYqw7tTUtLM0OFXcaOHeukpKSYobAjRoxw7r333lOG9uqwXk/0d6Pv9y1atDjlvVnXdTjuBRdcYK4t+rozMzOdjz/+uJKz9/N1ZfDgwaZM9evXd+6++25n5MiRTocOHSo9x7t373YGDhzoNGzY0ImLizNDX4cOHeq+Jq1bt86cAz3X559/vhlurOV//vnnnUBasGCBGaIcGxvrXHTRRc7ixYvL/FxfT+nz7hrK27ZtWychIcEMX7711lud7777rsw+eo3XYcKu1/rkk0+aodGBHNpbS//xpZlGZ23ToUCail20vUyr9LSzUXma1LXD6wMPPODepkl50aJFpmNQVWgzjdaQaFtoUlJSVYsLAKfQjof66VZHU+jMlQAC93+qqtdvn5pptL1IO/KUbqfSdiVd99ZOVZ12LQAAED18nvRMazl0alhto9P2MW1f0k5RrtE12j6l7VS+tGsBAFATOjzV2+Rh+jOENp+H9upkKTrhjY5T1k6oOkZbw4ark6r2dC7dW1d7L+vcItrjW3t+a0cfbaJhjhEAgL/ozf08zTyraN4PfT71GbGFPiMA/IU+I0CY9xkBAADwN8IIgKjk643dAATu/1K1bpQHAOFKRwVqvzadMl1nC9X1msyECkQrx3HMlB/aj1T/T9VkhlbCCICoom+a2ratU5ZrIAFQMzr/mM4pVn6qeV8QRgBEHf0Ep2+eegt1vcUFgOrR2xHoHZdrWrtIGAEQlfTNU2/C5ssdawEEBh1YAQCAVYQRAABgFWEEAABYFRZ9RlyTxOpMbgAAIDy4rtuVTfYeFmHk0KFD5mtqaqrtogAAgGpcx3Va+LC+N43O7qbzAdSrV8+vkxNpYtOAs3PnTu55E0Cc5+DhXAcH5zk4OM/hf541YmgQadq0aYXzkIRFzYi+gObNmwfs8fXk84ceeJzn4OFcBwfnOTg4z+F9niuqEXGhAysAALCKMAIAAKyK6jASFxcn48aNM18ROJzn4OFcBwfnOTg4z9FznsOiAysAAIhcUV0zAgAA7COMAAAAqwgjAADAKsIIAACwKuLDSE5OjrRs2VLi4+MlPT1d1qxZU+H+b775plx44YVm/4svvliWLFkStLJGy3meOXOmdO/eXRo0aGCWjIyMSn8vqP7ftMu8efPMDMY33HBDwMsYjed5//79Mnz4cGnSpIkZldC6dWvePwJwnqdOnSoXXHCBJCQkmFlDR4wYIceOHQtaecPRJ598Ir169TKzoOp7wKJFiyo9ZuXKlXLppZeav+XzzjtPZs+eHdhCOhFs3rx5TmxsrDNr1izn66+/doYOHerUr1/fKSws9Lj/Z5995sTExDiTJ092NmzY4IwZM8apW7eu89VXXwW97JF8nvv37+/k5OQ4X375pfPNN984gwcPdpKTk53vvvsu6GWP9HPtsm3bNqdZs2ZO9+7dneuvvz5o5Y2W83z8+HEnLS3N6dmzp7Nq1SpzvleuXOmsX78+6GWP5PP8+uuvO3FxcearnuNly5Y5TZo0cUaMGBH0soeTJUuWOKNHj3YWLlyoo2edt99+u8L9t27d6iQmJjpZWVnmWvjiiy+aa+PSpUsDVsaIDiOdO3d2hg8f7l4vLi52mjZt6mRnZ3vcv0+fPs51111XZlt6erpz1113Bbys0XSeyzt58qRTr149Z86cOQEsZfSeaz2/Xbt2dV555RVn0KBBhJEAnOfp06c75557rlNUVBTEUkbfedZ9r7766jLb9ILZrVu3gJc1UkgVwsjDDz/sXHTRRWW29e3b18nMzAxYuSK2maaoqEjy8vJME0Dpe9zoem5ursdjdHvp/VVmZqbX/VG981zekSNH5MSJE3LGGWcEsKTRe67Hjx8vjRo1kttvvz1IJY2+8/zuu+9Kly5dTDNNSkqKtGvXTiZNmiTFxcVBLHnkn+euXbuaY1xNOVu3bjVNYT179gxauaNBroVrYVjcKK869u7da94I9I2hNF3fuHGjx2MKCgo87q/b4b/zXN4jjzxi2jLL//Gj5ud61apV8uqrr8r69euDVMroPM96Ufzwww/l1ltvNRfHLVu2yD333GNCts5sCf+c5/79+5vjLr/8cnM32JMnT8qwYcPk0UcfDVKpo0OBl2uh3t336NGjpr+Ov0VszQjCw1NPPWU6Vr799tumAxv8R2/bPWDAANNhuGHDhraLE9FKSkpM7dPLL78snTp1kr59+8ro0aNlxowZtosWUbRTpdY4TZs2TdatWycLFy6UxYsXy4QJE2wXDTUUsTUj+uYbExMjhYWFZbbreuPGjT0eo9t92R/VO88uzz77rAkjy5cvl/bt2we4pNF3rr/99lvZvn276UVf+qKp6tSpI5s2bZJWrVoFoeSR/zetI2jq1q1rjnNp06aN+YSpzRGxsbEBL3c0nOfHHnvMBOw77rjDrOuIx8OHD8udd95pwp8286DmvF0Lk5KSAlIroiL2N6f/+fUTyooVK8q8Eeu6tu16ottL768++OADr/ujeudZTZ482XyaWbp0qaSlpQWptNF1rnWI+ldffWWaaFxL7969pUePHuZ7HRYJ//xNd+vWzTTNuMKe2rx5swkpBBH/nWftX1Y+cLgCILdZ8x8r10InwoeN6TCw2bNnm+FJd955pxk2VlBQYH4+YMAAZ+TIkWWG9tapU8d59tlnzZDTcePGMbQ3AOf5qaeeMsP53nrrLWf37t3u5dChQxZfRWSe6/IYTROY85yfn29GhN17773Opk2bnPfee89p1KiRM3HiRIuvIvLOs74n63l+4403zPDTf/7zn06rVq3MSEh4p++tOpWCLnrZnzJlivl+x44d5ud6jvVclx/a+9BDD5lroU7FwNDeGtLx0Weffba5+Okwss8//9z9syuvvNK8OZe2YMECp3Xr1mZ/Hdq0ePFiC6WO7PPcokUL8x+i/KJvNPD/33RphJHAnefVq1ebqQD04qrDfJ988kkzrBr+O88nTpxwHn/8cRNA4uPjndTUVOeee+5x9u3bZ6n04eGjjz7y+J7rOrf6Vc91+WM6duxofi/69/zaa68FtIy19J/A1bsAAABEaZ8RAAAQHggjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAAxKb/B6c1bIkqxYZhAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.80       100\n",
      "           1       0.80      0.81      0.81       100\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.81      0.81      0.80       200\n",
      "weighted avg       0.81      0.81      0.80       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 임의로 만드는것 ( 존재X)\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve , auc , classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "X,y = make_classification(n_samples=1000 , n_features=20 , n_informative=5 , n_redundant=0 , random_state=42)\n",
    "\n",
    "X_train, X_test , y_train , y_test = train_test_split(X , y , test_size=0.2 , random_state=42 , stratify=y)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train , y_train)\n",
    "\n",
    "# 그래프를 그릴때 확률이 필요함\n",
    "y_pred_proba = model.predict_proba(X_test)[:,1] # 양성값만 나타냄\n",
    "\n",
    "# ROC AUC\n",
    "# 실제값과 예측 확률을 사용 FPR TPR\n",
    "# 순서가 중요함\n",
    "fpr , tpr , thresholds = roc_curve(y_test , y_pred_proba)\n",
    "\n",
    "# FPR TPR 이용 AUC를 계산\n",
    "roc_auc = auc(fpr , tpr)\n",
    "\n",
    "plt.plot(fpr , tpr , label=f'ROC curve_area = {roc_auc:.2f}')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 모델만 머신러닝이지 평가나 시각화는 딥러닝도 비슷함\n",
    "print(classification_report( y_test, model.predict(X_test)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a5c20e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
