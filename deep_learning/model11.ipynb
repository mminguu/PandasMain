{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "525adbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가우스 잡음 추가 함수\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "692b05b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1l/rpxsxc3j1b15kw96kqt86gh80000gn/T/ipykernel_7134/3987532287.py:2: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gaussian_data_x = x + np.random.normal(\n",
      "/var/folders/1l/rpxsxc3j1b15kw96kqt86gh80000gn/T/ipykernel_7134/3987532287.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gaussian_data_x = torch.tensor(gaussian_data_x , dtype=torch.float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x311267750>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def gaussian_noise(x , scale=0.8):\n",
    "    gaussian_data_x = x + np.random.normal(\n",
    "        loc = 0 , scale=scale , size = x.shape\n",
    "    )\n",
    "    gaussian_data_x = np.clip(gaussian_data_x)\n",
    "    gaussian_data_x = torch.tensor(gaussian_data_x , dtype=torch.float32)\n",
    "    return gaussian_data_x\n",
    "\n",
    "train_data = MNIST(root='./' , train=True , download=True , transform=ToTensor())\n",
    "test_data = MNIST(root='./' , train=False , download=True , transform=ToTensor())\n",
    "\n",
    "img , label = next(iter(train_data))\n",
    "img\n",
    "gaussian = gaussian_noise(img)\n",
    "gaussian\n",
    "\n",
    "img = img.permute(1,2,0)\n",
    "gaussian = gaussian.permute(1,2,0)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(gaussian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cd81f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1l/rpxsxc3j1b15kw96kqt86gh80000gn/T/ipykernel_7134/3987532287.py:2: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  gaussian_data_x = x + np.random.normal(\n",
      "/var/folders/1l/rpxsxc3j1b15kw96kqt86gh80000gn/T/ipykernel_7134/3987532287.py:6: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  gaussian_data_x = torch.tensor(gaussian_data_x , dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "for data , label in train_data:\n",
    "    noisy = gaussian_noise(data)\n",
    "    print(type(noisy),noisy.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5bab797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습용 데이터셋\n",
    "from torch.utils.data.dataset import Dataset\n",
    "class Denise(Dataset):\n",
    "    def __init__(self):\n",
    "        self.mnist = train_data = MNIST(root='./' , train=True , download=True , transform=ToTensor())\n",
    "        self.data = []\n",
    "        # 잡음 입히기\n",
    "        for data , label in self.mnist:\n",
    "            noisy = gaussian_noise(data)\n",
    "            self.data.append(noisy.unsqueeze(0)) # (1(channel),1(h),28(w),28(w))\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        label = self.mnist.data[index] / 255 # 원본 이미지도 0~1 정규화\n",
    "        return data , label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2283b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱 기본 블럭\n",
    "# conv -> relu -> conv -> relu\n",
    "import torch.nn as nn\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self,in_channel , out_channel , hidden_channel):\n",
    "        super(BasicBlock,self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channel ,  hidden_channel , kernel_size=3 , padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_channel ,  out_channel , kernel_size=3 , padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "# sample_data = torch.randn(1,1,28,28)\n",
    "# sample_model = BasicBlock(1,20,10)\n",
    "# sample_model(sample_data).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67a2779e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.conv1 = BasicBlock(1,16,16)\n",
    "        self.conv2 = BasicBlock(16,8,8)\n",
    "        self.pool = nn.AvgPool2d(2)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x)) # 1 , 16 , 14 , 41\n",
    "        out = self.pool(self.conv2(x)) # 1 , 8 , 7 , 7\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec78cdfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.conv1 = BasicBlock(8,8,8)\n",
    "        self.conv2 = BasicBlock(8,16,16)\n",
    "        # 출력층\n",
    "        self.conv3 = nn.Conv2d(16,1,kernel_size=3,padding=1)\n",
    "        # 어셈플링 층\n",
    "        self.upsampling1 = nn.ConvTranspose2d(8,8,kernel_size=2 , stride=2)\n",
    "        self.upsampling2 = nn.ConvTranspose2d(16,16,kernel_size=2 , stride=2)\n",
    "    def forward(self, x):\n",
    "        x = self.upsampling1(self.conv1(x))\n",
    "        x = self.upsampling2(self.conv2(x))\n",
    "        out = self.conv3(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb442f8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "conv2d() received an invalid combination of arguments - got (type, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!type!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = \"valid\", tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!type!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m d \u001b[38;5;241m=\u001b[39m Decoder()\n\u001b[0;32m----> 2\u001b[0m d(Encoder)\u001b[38;5;241m.\u001b[39msize()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsampling1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x))\n\u001b[1;32m     13\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupsampling2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))\n\u001b[1;32m     14\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;124;03mRuns the forward pass.\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/conv.py:548\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.13/site-packages/torch/nn/modules/conv.py:543\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    533\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    534\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    542\u001b[0m     )\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups\n\u001b[1;32m    545\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: conv2d() received an invalid combination of arguments - got (type, Parameter, Parameter, tuple, tuple, tuple, int), but expected one of:\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, tuple of ints padding = 0, tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!type!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n * (Tensor input, Tensor weight, Tensor bias = None, tuple of ints stride = 1, str padding = \"valid\", tuple of ints dilation = 1, int groups = 1)\n      didn't match because some of the arguments have invalid types: (!type!, !Parameter!, !Parameter!, !tuple of (int, int)!, !tuple of (int, int)!, !tuple of (int, int)!, !int!)\n"
     ]
    }
   ],
   "source": [
    "d = Decoder()\n",
    "d(Encoder).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4205cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAE 모델로 Auto Encoder 연결할꺼임.\n",
    "# Decoder 와 Encoder 를 연결 : 인코더의 출력을 디코더의 입력으로 제공\n",
    "class CAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CAE , self).__init__()\n",
    "        self.enc = Encoder()\n",
    "        self.dec = Decoder()\n",
    "    def forward(self,x):\n",
    "        x = self.enc(x)\n",
    "        x = self.dec(x)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
