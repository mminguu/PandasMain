{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06384b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor (다차원배열)\n",
    "# 데이터를 저장하는 다차원 배열 또는 컨테이너 배열\n",
    "# 딥러닝이 학습할때 사용하는 자료구조\n",
    "# 0차원 Tensor (스칼라) : 0이나 1처럼 단일 데이터를 뜻함.\n",
    "# 1차원 Tensor (백터) : 리스트 형태로 [1,2,3,4] 로 보면 됌\n",
    "# 2차원 Tensor (행렬) : 행과 열로 이루어진 데이터로 표데이터 , 흑백이미지 (가로픽셀 x 세로픽셀)\n",
    "# 3차원 Tensor (컬러이미지) : 흑백이미지 + 채널정보(R G B)\n",
    "# 고차원 Tensor (동영상) : 이미지개수 x 가로픽셀 x 세로픽셀 x 채널정보(R G B)\n",
    "# 데이터의 표준형식 : 일관된 숫자 형식\n",
    "# 효율적인 계산 : GPU를 지원하기때문에 병렬 계산에 유리함.\n",
    "# 딥러닝 프레임워크 : 텐서플로 , 파이토치(페이스북에서 개발한 머신러닝라이브러리/동적)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fafa121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.9.0-cp313-cp313-win_amd64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.24.0-cp313-cp313-win_amd64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\playdata\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Using cached fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\playdata\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\playdata\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision) (2.3.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\playdata\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Using cached torch-2.9.0-cp313-cp313-win_amd64.whl (109.3 MB)\n",
      "Using cached torchvision-0.24.0-cp313-cp313-win_amd64.whl (4.3 MB)\n",
      "Using cached fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Installing collected packages: fsspec, torch, torchvision\n",
      "\n",
      "   ---------------------------------------- 0/3 [fsspec]\n",
      "   ---------------------------------------- 0/3 [fsspec]\n",
      "   ---------------------------------------- 0/3 [fsspec]\n",
      "   ---------------------------------------- 0/3 [fsspec]\n",
      "   ---------------------------------------- 0/3 [fsspec]\n",
      "   ---------------------------------------- 0/3 [fsspec]\n",
      "   ---------------------------------------- 0/3 [fsspec]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   ------------- -------------------------- 1/3 [torch]\n",
      "   -------------------------- ------------- 2/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchvision]\n",
      "   -------------------------- ------------- 2/3 [torchvision]\n",
      "   ---------------------------------------- 3/3 [torchvision]\n",
      "\n",
      "Successfully installed fsspec-2025.9.0 torch-2.9.0 torchvision-0.24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The scripts torchfrtrace.exe and torchrun.exe are installed in 'c:\\Users\\playdata\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision  # 파이토치 설치  /  torchvision <- deeplearning 에 사용됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff9a177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 기본연산\n",
    "#  파이토치는 numpy의 array와 유사함.\n",
    "import torch\n",
    "\n",
    "# 빈 Tensor 생성\n",
    "x = torch.empty(3,4)\n",
    "print(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e767ae8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9892, 0.2093, 0.6946, 0.6795],\n",
       "        [0.7995, 0.6019, 0.2199, 0.2067],\n",
       "        [0.5100, 0.3235, 0.1675, 0.7774]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤 Tensor\n",
    "# empty나 rand가 비슷함 \n",
    "x = torch.rand(3,4)\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ecf063f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0],\n",
       "        [0, 0, 0, 0],\n",
       "        [0, 0, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0으로 Tensor 초기화\n",
    "torch.zeros(3,4,dtype=torch.long) # 데이터타입을 세밍하게 지정해주는 경우가 좋음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b046672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1로 Tensor 초기화\n",
    "torch.ones(3,4,dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1dfe1a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.5, 3, 2.1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[3.5,3,2.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d2ff763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.5000, 3.0000, 2.1000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([3.5,3,2.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abdd8632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.5000, 3.0000, 2.1000])\n",
      "[3.5 3.  2.1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print( torch.tensor([3.5,3,2.1]) )\n",
    "print( np.array( [3.5,3,2.1] ) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a115082c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.],\n",
       "         [1., 1., 1., 1.]]),\n",
       " tensor([[0.2146, 0.5719, 0.9002, 0.9201],\n",
       "         [0.2142, 0.2211, 0.8783, 0.1829],\n",
       "         [0.6651, 0.5096, 0.0063, 0.0216]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기존의 Tensor를 기번으로 새로운 Tensor 생성 가능 (복사하는 기능이 있음)\n",
    "\n",
    "x = torch.ones(3,4)\n",
    "y = torch.rand_like( x,dtype=torch.float)\n",
    "x , y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925f4c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4693, 0.1617, 0.9426, 0.7226],\n",
       "         [0.8220, 0.0655, 0.4329, 0.9880],\n",
       "         [0.2302, 0.9869, 0.6609, 0.6436]]),\n",
       " tensor([[0.1655, 0.1412, 0.0971, 0.2987],\n",
       "         [0.1540, 0.3969, 0.1952, 0.3999],\n",
       "         [0.8497, 0.3598, 0.8874, 0.3569]]),\n",
       " tensor([[0.6348, 0.3028, 1.0398, 1.0213],\n",
       "         [0.9759, 0.4624, 0.6281, 1.3879],\n",
       "         [1.0799, 1.3466, 1.5483, 1.0006]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor 연산해보자\n",
    "\n",
    "import torch\n",
    "\n",
    "x = torch.rand(3,4)\n",
    "y = torch.rand(3,4)\n",
    "\n",
    "x,y,x+y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5dabf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6348, 0.3028, 1.0398, 1.0213],\n",
       "        [0.9759, 0.4624, 0.6281, 1.3879],\n",
       "        [1.0799, 1.3466, 1.5483, 1.0006]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x,y) # 이렇게 덧셈해도 됌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1622a83f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6348, 0.3028, 1.0398, 1.0213],\n",
       "        [0.9759, 0.4624, 0.6281, 1.3879],\n",
       "        [1.0799, 1.3466, 1.5483, 1.0006]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in-place : 판다스에서는 in-place를 사용하면 자기 자신을 바꿔주지만 \n",
    "# Tensor에서는 메서드 이름 뒤에 _(언더스코어)를 붙여서 사용함.\n",
    "\n",
    "y.add_(x) # y = y + x (y 자체를 변경!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f05406d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 9])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1차원 곱셈은 이렇게 진행됨\n",
    "x = torch.tensor( [1,2,3] )\n",
    "y = torch.tensor( [1,2,3] )\n",
    "\n",
    "x*y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f47171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4781, 0.5668, 0.9249, 0.1812],\n",
       "         [0.3692, 0.8060, 0.0409, 0.4769],\n",
       "         [0.6761, 0.1596, 0.4259, 0.7189]]),\n",
       " tensor([[0.6807, 0.6069, 0.7694, 0.1838, 0.1722],\n",
       "         [0.9822, 0.0623, 0.2868, 0.1571, 0.5582],\n",
       "         [0.0881, 0.8583, 0.4352, 0.1100, 0.6312],\n",
       "         [0.5588, 0.6212, 0.7658, 0.0089, 0.3921]]),\n",
       " tensor([[1.0649, 1.2319, 1.0717, 0.2803, 1.0535],\n",
       "         [1.3131, 0.6057, 0.8983, 0.2032, 0.7262],\n",
       "         [1.0562, 1.2324, 1.3019, 0.2026, 0.7562]]),\n",
       " tensor([[1.0649, 1.2319, 1.0717, 0.2803, 1.0535],\n",
       "         [1.3131, 0.6057, 0.8983, 0.2032, 0.7262],\n",
       "         [1.0562, 1.2324, 1.3019, 0.2026, 0.7562]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 행렬 곱셈\n",
    "# 양쪽의 행렬 중 첫번째 행렬에서 열과 두번째 행렬에서 행의 숫자가 동일해야 연산이 가능 \n",
    "# 행렬의 곱셈 후 표시는 첫번째 행 , 두번째 열로 표시됨\n",
    "\n",
    "\n",
    "x = torch.rand(3,4)\n",
    "y = torch.rand(4,5)\n",
    "\n",
    "x,y,torch.mm(x,y) , x@y # torch.mm(x,y) 출력 값이 python 3.5버전부터 x@y로도 동일한 값이 나옴."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eed041ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9821, 0.7042, 0.8858])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 슬라이싱 가능\n",
    "\n",
    "x = torch.rand(4,5)\n",
    "x[0,2:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e001e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4377), 0.4376525282859802)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 행렬의 특정요소를 찾는법\n",
    "\n",
    "x[1,1], x[1,1].item() #item()을 쓰면 데이터타입이 다르게 출력됨\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187ae4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Tensor, float)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU에서 돌아가는 구조.\n",
    "# \n",
    "type(x[1,1]) , type(x[1,1].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad23047d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5491, 0.2102, 0.1555, 0.7151],\n",
       "         [0.9916, 0.9246, 0.8223, 0.7142],\n",
       "         [0.7903, 0.0236, 0.8948, 0.0021],\n",
       "         [0.5287, 0.5571, 0.5725, 0.4135]]),\n",
       " tensor([0.5491, 0.2102, 0.1555, 0.7151, 0.9916, 0.9246, 0.8223, 0.7142, 0.7903,\n",
       "         0.0236, 0.8948, 0.0021, 0.5287, 0.5571, 0.5725, 0.4135]),\n",
       " torch.Size([4, 4]),\n",
       " torch.Size([16]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor 크기 변경\n",
    "# numpy 동일한 기능 reshape\n",
    "\n",
    "x = torch.rand(4,4)\n",
    "y = x.view(16)  # view(-1) 여기서 -1 은 자동 계산\n",
    "x,y,x.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "43e9b79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x 는 4행 4열\n",
    "x.view(2,8) # 2밖에 올 수 없으니 자동계산인 -1을 넣어도 됌\n",
    "x.view(-1,8) # 확실히 값을 아는 경우에만 자동 계산인 -1을 넣어줘야함\n",
    "x.size() # shape랑 똑같은 기능.\n",
    "\n",
    "# view는 reshpe와 동일함. tensor 모양 변경\n",
    "# size는 shape와 동일함. tnesor 모양 확인\n",
    "# 가독성 view size가 사용되었다는 것은 해당 자료구조가 tensor라는것을 명시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5be1a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor -> numpy 바꾸기\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "a = torch.ones(5)\n",
    "# np.array(a)\n",
    "a.numpy()  # tensor 자체에 numpy를 해주는것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "463d58b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy -> tensor 바꾸기\n",
    "\n",
    "a = np.array( [1,2,3,4,5] )\n",
    "torch.from_numpy(a) # torch에 numpy를 하면 tensor로 바뀜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7c96f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU 사용 -> cuda를 쓰면 GPU를 쓰겠단거임.\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467e5deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda를 사용할 수 없다\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda') # GPU (병렬로 연산)\n",
    "    #tensor들은 GPU에서 연산해야되기때문에 생성을 GPU에서 생성\n",
    "    x = torch.ones(5,device=device) #GPU에서 생성\n",
    "    y = torch.ones(5) # CPU 에서 생성\n",
    "    y = y.to(device) # CPU -> GPU로 이동 / to('소문자)\n",
    "    z = x + y\n",
    "    print(f'GPU 연산결과 : {z}')\n",
    "    print(f'다시 CPU로 : {z.to(\"cpu\",torch.double)}')\n",
    "else:\n",
    "    print('cuda를 사용할 수 없다')\n",
    "    device = torch.device('CPU')\n",
    "\n",
    "# 코랩에서 확인 가능\n",
    "# torch.cuda.is_available() <- 코랩에서는 True로 나옴.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4fd04d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 행열의 곱\n",
    "# ( x,y )  *  ( x1,y1 )\n",
    "# # y , x1 의 차수는 같아야함.\n",
    "# 행열곱의 결과의 최종은 x , y1 \n",
    "\n",
    "# Tensor는 딥러닝을 위해 만들 저료구조\n",
    "# 내부에 GPU 연산에 특화된 구조임.\n",
    "# 일반적인 모양은 numpy와 동일함.\n",
    "\n",
    "# Tensor는 GPU 연산을 지원함.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d1a4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor에는 자동미분 기능이 있음 . \n",
    "\n",
    "# 자동미분(Autograd) : 매 계산 과정마다 계산 과정의 미분값을 저장하고 있는 것.\n",
    "# 파이토치 required_grad = True 로 설정하면 계산그래프 형태로 기록 ( 동영상 녹화와 비슷한 원리 )\n",
    "# .backword() 호출하면 이 과정을 거꾸로 되감으면서 각 단계의 미분값을 계산 해 최종 기울기를 얻는다.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "325f0dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1.],\n",
       "         [1., 1.]], requires_grad=True),\n",
       " torch.Size([2, 2]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2,2, requires_grad=True)\n",
    "x , x.size() # 배열보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fda5c64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [3., 3.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x + 2 # y 도 계산 그래프에 추가\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1e012f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AddBackward0 at 0x23e6b185b70>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "63b265b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[27., 27.],\n",
       "         [27., 27.]], grad_fn=<MulBackward0>),\n",
       " tensor(27., grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "z , out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "070d072a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.5000, 4.5000],\n",
       "        [4.5000, 4.5000]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 기울기를 구하는 과정을 '역전파' 라고 함 --> 기울기 계산  //  backword() 를 사용하면 됌\n",
    "\n",
    "# 최종결과가 out에서부터 시작해서 계산 그래프를 가꾸로 거슬러 오라가면서 미분의 연쇄법칙을 사용하여 미분값을 계산.\n",
    "# out을 x에 대해서 미분\n",
    "\n",
    "out.backward()\n",
    "x.grad\n",
    "# 최종 기울기는 x가 가지고 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2f16b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# out = 1/4*(z1 + z2 + z3 + z4)\n",
    "# z = 3y^2\n",
    "# y = x + 2\n",
    "\n",
    "#d-out / dxi = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "463245f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0987, -1.2551, -0.3874], requires_grad=True)\n",
      "y : tensor([ 1125.1118, -1285.2572,  -396.7133], grad_fn=<MulBackward0>)\n",
      "반복횟수 : 9  y = x*2^i+1\n",
      "x.grad : tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])\n"
     ]
    }
   ],
   "source": [
    "# 기울기 제어\n",
    "# 역전파 , torch.no_grad , detach\n",
    "# required_grad = True 연산 추척\n",
    "import torch\n",
    "x = torch.randn(3, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "# y 는 x 로부터 연산기록을 물려받음\n",
    "y = x * 2\n",
    "y.data  # 순수한 데이터에만 접근함.\n",
    "# 노름 (유클리드 노름)  벡터의 크기를 측정하는 방법(원점으로부터 벡터까지의 거리)  모든 요소를 각각 제곱하고 모두 더해서 결과에 제곱근(루트)\n",
    "# y의 실제 데이터의 크기를 확인해서 반복\n",
    "i = 0\n",
    "while y.data.norm()  < 1000:\n",
    "    y = y*2\n",
    "    i += 1\n",
    "print(f'y : {y}')\n",
    "print(f'반복횟수 : {i}  y = x*2^i+1')\n",
    "\n",
    "# 벡터에 대한 역전파 (야코비안 행열)\n",
    "# 벡터를 벡터로 미분하면 결과는 행열인 야코비안 행열\n",
    "# pytorch 는 전체 야코비안 행열을 직접 계산하는 대신 야코비안 - 벡터 곱을 계산해서 메모리를 절약\n",
    "v = torch.tensor( [0.1,1.0,0.0001],dtype=torch.float )\n",
    "y.backward(v)  # y를 x에 대해 미분한 야코비안 행열과 입력으로 제공된 벡터 v를 곱하라는 의미\n",
    "\n",
    "print(f'x.grad : {x.grad}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c698fb",
   "metadata": {},
   "source": [
    "'''\n",
    "1. 스칼라 백워드 Scalar Backward : 역전파로 구하는 기울기가 하나일때\n",
    "    out.backward()\n",
    "    최종점수가 숫자 1개  ex)  수학공부 1시간 했을때 최종점수에 몇점의 영향을 줬는지 (미분)\n",
    "    최종 목표가 하나(스칼라) 이기 때문에 각 원인(각 변수)의 기여도를 바로 계산\n",
    "\n",
    "2. 벡터 백워드 Vector Backward : 기울기가 여러개일때\n",
    "    y.vackward(v)\n",
    "    과목별(국영수) 점수가 담긴 성적표(벡터)  ex) 공부시간이 성적에 얼마나 영향을 줬는지 물어보면 애매, 국어성적인지 영어성적인지.\n",
    "    가중치 또는 중요도를 알려주는 벡터가 필요하다~  v = torch.tensor( [0.1,1.0,0.0001],dtype=torch.float )\n",
    "    중요도를 반영해서 최종적으로 공부시간의 기여도를 확인한다는 것.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b705729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_grad 내부 : False\n"
     ]
    }
   ],
   "source": [
    "# 각 학습을 진행하면서 도중에 모델의 성능을 평가할 필요성이 있음 - 기울기 계산을 하면 안됨\n",
    "with torch.no_grad():\n",
    "    print(f'no_grad 내부 : {(x**2).requires_grad}')\n",
    "\n",
    "\n",
    "# .derach()  계산그래프에서 tensor를 분리\n",
    "print(f'detach 전 {y.requires_grad}')\n",
    "y = x.detach()\n",
    "print(f'detach 후 {y.requires_grad}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac36f8f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
