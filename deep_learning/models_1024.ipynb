{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4aed0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in d:\\pandas_main\\.venv\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: filelock in d:\\pandas_main\\.venv\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\pandas_main\\.venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in d:\\pandas_main\\.venv\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in d:\\pandas_main\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in d:\\pandas_main\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in d:\\pandas_main\\.venv\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in d:\\pandas_main\\.venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\pandas_main\\.venv\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\pandas_main\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13457b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0+cpu 0.24.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "print(torch.__version__, torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50a22eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models # 이미 만들어진 유명한 딥러닝 모델들”을 불러오는 구문이야"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14741d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlexNet',\n",
       " 'AlexNet_Weights',\n",
       " 'ConvNeXt',\n",
       " 'ConvNeXt_Base_Weights',\n",
       " 'ConvNeXt_Large_Weights',\n",
       " 'ConvNeXt_Small_Weights',\n",
       " 'ConvNeXt_Tiny_Weights',\n",
       " 'DenseNet',\n",
       " 'DenseNet121_Weights',\n",
       " 'DenseNet161_Weights',\n",
       " 'DenseNet169_Weights',\n",
       " 'DenseNet201_Weights',\n",
       " 'EfficientNet',\n",
       " 'EfficientNet_B0_Weights',\n",
       " 'EfficientNet_B1_Weights',\n",
       " 'EfficientNet_B2_Weights',\n",
       " 'EfficientNet_B3_Weights',\n",
       " 'EfficientNet_B4_Weights',\n",
       " 'EfficientNet_B5_Weights',\n",
       " 'EfficientNet_B6_Weights',\n",
       " 'EfficientNet_B7_Weights',\n",
       " 'EfficientNet_V2_L_Weights',\n",
       " 'EfficientNet_V2_M_Weights',\n",
       " 'EfficientNet_V2_S_Weights',\n",
       " 'GoogLeNet',\n",
       " 'GoogLeNetOutputs',\n",
       " 'GoogLeNet_Weights',\n",
       " 'Inception3',\n",
       " 'InceptionOutputs',\n",
       " 'Inception_V3_Weights',\n",
       " 'MNASNet',\n",
       " 'MNASNet0_5_Weights',\n",
       " 'MNASNet0_75_Weights',\n",
       " 'MNASNet1_0_Weights',\n",
       " 'MNASNet1_3_Weights',\n",
       " 'MaxVit',\n",
       " 'MaxVit_T_Weights',\n",
       " 'MobileNetV2',\n",
       " 'MobileNetV3',\n",
       " 'MobileNet_V2_Weights',\n",
       " 'MobileNet_V3_Large_Weights',\n",
       " 'MobileNet_V3_Small_Weights',\n",
       " 'RegNet',\n",
       " 'RegNet_X_16GF_Weights',\n",
       " 'RegNet_X_1_6GF_Weights',\n",
       " 'RegNet_X_32GF_Weights',\n",
       " 'RegNet_X_3_2GF_Weights',\n",
       " 'RegNet_X_400MF_Weights',\n",
       " 'RegNet_X_800MF_Weights',\n",
       " 'RegNet_X_8GF_Weights',\n",
       " 'RegNet_Y_128GF_Weights',\n",
       " 'RegNet_Y_16GF_Weights',\n",
       " 'RegNet_Y_1_6GF_Weights',\n",
       " 'RegNet_Y_32GF_Weights',\n",
       " 'RegNet_Y_3_2GF_Weights',\n",
       " 'RegNet_Y_400MF_Weights',\n",
       " 'RegNet_Y_800MF_Weights',\n",
       " 'RegNet_Y_8GF_Weights',\n",
       " 'ResNeXt101_32X8D_Weights',\n",
       " 'ResNeXt101_64X4D_Weights',\n",
       " 'ResNeXt50_32X4D_Weights',\n",
       " 'ResNet',\n",
       " 'ResNet101_Weights',\n",
       " 'ResNet152_Weights',\n",
       " 'ResNet18_Weights',\n",
       " 'ResNet34_Weights',\n",
       " 'ResNet50_Weights',\n",
       " 'ShuffleNetV2',\n",
       " 'ShuffleNet_V2_X0_5_Weights',\n",
       " 'ShuffleNet_V2_X1_0_Weights',\n",
       " 'ShuffleNet_V2_X1_5_Weights',\n",
       " 'ShuffleNet_V2_X2_0_Weights',\n",
       " 'SqueezeNet',\n",
       " 'SqueezeNet1_0_Weights',\n",
       " 'SqueezeNet1_1_Weights',\n",
       " 'SwinTransformer',\n",
       " 'Swin_B_Weights',\n",
       " 'Swin_S_Weights',\n",
       " 'Swin_T_Weights',\n",
       " 'Swin_V2_B_Weights',\n",
       " 'Swin_V2_S_Weights',\n",
       " 'Swin_V2_T_Weights',\n",
       " 'VGG',\n",
       " 'VGG11_BN_Weights',\n",
       " 'VGG11_Weights',\n",
       " 'VGG13_BN_Weights',\n",
       " 'VGG13_Weights',\n",
       " 'VGG16_BN_Weights',\n",
       " 'VGG16_Weights',\n",
       " 'VGG19_BN_Weights',\n",
       " 'VGG19_Weights',\n",
       " 'ViT_B_16_Weights',\n",
       " 'ViT_B_32_Weights',\n",
       " 'ViT_H_14_Weights',\n",
       " 'ViT_L_16_Weights',\n",
       " 'ViT_L_32_Weights',\n",
       " 'VisionTransformer',\n",
       " 'Weights',\n",
       " 'WeightsEnum',\n",
       " 'Wide_ResNet101_2_Weights',\n",
       " 'Wide_ResNet50_2_Weights',\n",
       " '_GoogLeNetOutputs',\n",
       " '_InceptionOutputs',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_api',\n",
       " '_meta',\n",
       " '_utils',\n",
       " 'alexnet',\n",
       " 'convnext',\n",
       " 'convnext_base',\n",
       " 'convnext_large',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'densenet',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'detection',\n",
       " 'efficientnet',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_v2_l',\n",
       " 'efficientnet_v2_m',\n",
       " 'efficientnet_v2_s',\n",
       " 'get_model',\n",
       " 'get_model_builder',\n",
       " 'get_model_weights',\n",
       " 'get_weight',\n",
       " 'googlenet',\n",
       " 'inception',\n",
       " 'inception_v3',\n",
       " 'list_models',\n",
       " 'maxvit',\n",
       " 'maxvit_t',\n",
       " 'mnasnet',\n",
       " 'mnasnet0_5',\n",
       " 'mnasnet0_75',\n",
       " 'mnasnet1_0',\n",
       " 'mnasnet1_3',\n",
       " 'mobilenet',\n",
       " 'mobilenet_v2',\n",
       " 'mobilenet_v3_large',\n",
       " 'mobilenet_v3_small',\n",
       " 'mobilenetv2',\n",
       " 'mobilenetv3',\n",
       " 'optical_flow',\n",
       " 'quantization',\n",
       " 'regnet',\n",
       " 'regnet_x_16gf',\n",
       " 'regnet_x_1_6gf',\n",
       " 'regnet_x_32gf',\n",
       " 'regnet_x_3_2gf',\n",
       " 'regnet_x_400mf',\n",
       " 'regnet_x_800mf',\n",
       " 'regnet_x_8gf',\n",
       " 'regnet_y_128gf',\n",
       " 'regnet_y_16gf',\n",
       " 'regnet_y_1_6gf',\n",
       " 'regnet_y_32gf',\n",
       " 'regnet_y_3_2gf',\n",
       " 'regnet_y_400mf',\n",
       " 'regnet_y_800mf',\n",
       " 'regnet_y_8gf',\n",
       " 'resnet',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_64x4d',\n",
       " 'resnext50_32x4d',\n",
       " 'segmentation',\n",
       " 'shufflenet_v2_x0_5',\n",
       " 'shufflenet_v2_x1_0',\n",
       " 'shufflenet_v2_x1_5',\n",
       " 'shufflenet_v2_x2_0',\n",
       " 'shufflenetv2',\n",
       " 'squeezenet',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'swin_b',\n",
       " 'swin_s',\n",
       " 'swin_t',\n",
       " 'swin_transformer',\n",
       " 'swin_v2_b',\n",
       " 'swin_v2_s',\n",
       " 'swin_v2_t',\n",
       " 'vgg',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'video',\n",
       " 'vision_transformer',\n",
       " 'vit_b_16',\n",
       " 'vit_b_32',\n",
       " 'vit_h_14',\n",
       " 'vit_l_16',\n",
       " 'vit_l_32',\n",
       " 'wide_resnet101_2',\n",
       " 'wide_resnet50_2']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(models) # 지금 불러온 models 안에 뭐가 들어 있는지 보여줘!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1d71c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "alexnet = models.AlexNet()\n",
    "print(alexnet)\n",
    "# 2012년 이미지 인식 혁명 일으킨 CNN 모델 -> CNN:이미지’를 보고 이해할 수 있도록 만들어진 딥러닝 모델\n",
    "# CNN은 보통 이렇게 구성돼:\n",
    "# Convolution 층 (Conv2d) → 특징을 추출\n",
    "# ReLU 층 → 음수 없애고 활성화\n",
    "# Pooling 층 (MaxPool2d) → 중요한 정보만 남기기\n",
    "# Flatten → Fully Connected(Linear) → 분류 결과 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "657a8d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 활성화 함수\n",
    "# Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09d5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet-101 : Residual Network(잔차 신경망)”의 줄임말\n",
    "# 깊어질수록 원래는 학습이 어려워지는데, ResNet은 특별한 지름길로 이 문제를 해결\n",
    "# 그 지름길의 이름은 (스킵커넥션 (Skip Connection , Residual Block))\n",
    "# 이 지름길을 포함한 작은 묶음을 Residual Block(잔차 블록) 이라고 불러.\n",
    "# Skip Connection - “완전히 새로운 걸 다” 가 아니라 기존 행동과의 차이만 배우게 하는 거야.\n",
    "# W, x를 직접 다 학습하는 대신 𝑓(𝑥)f(x) = 잔차(residual)만 학습\n",
    "# 초기x의 값이 지름길을 통해 뒤쪽 레이어까지 직접 전달\n",
    "# 깊은 신경망은 역전파할 때 기울기(gradient) 가 점점 작아져서 소실되기 쉽다.\n",
    "# 스킵 커넥션이 있으면, 역전파할 때 기울기가 지름길을 통해 ‘직접’ 초반층까지 전달된다.\n",
    "# 레이어가 100층 넘으면 소실/폭발이 필연적 → ResNet은 이걸 해결 -> 더 깊은 층을 볼 수 있게 됨\n",
    "# H(x) = F(x) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6620de68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pandas_main\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "d:\\pandas_main\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = models.resnet101(pretrained = False)\n",
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e646c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# PIL : 파이썬에게 사진을 열고, 자르고, 저장하고, 바꾸는 능력을 주는 도구 세트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2916117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alexnet.eval() 모델을 평가할때 평가모드로 전환하는 것 - 이제 공부 그만, 시험 보자!\n",
    "# PyTorch에서는 모델을 두 가지 모드로 나눠서 동작시켜\n",
    "# 1) 학습 모드 (training mode) - model.train() / 2) 평가 모드 (evaluation mode) - model.eval()\n",
    "# 배치정규화 : 훈련할 때의 경험(통계)”을 그대로 사용해서 예측을 안정화시키는 거야.\n",
    "# 학습을 안정적으로” 하게 도와주는 층으로 훈련할 때는 각 미니배치(batch) 마다\n",
    "# 평균(mean)과 분산(variance)을 즉석 계산해서 사용해\n",
    "# 하지만 평가할 때는,“전체 데이터에서 평균적으로 어떤 값이었는지”를 사용해야 안정적이지!\n",
    "# 드랍아웃 : 이건 학습 중에 과적합(외워버리는 문제) 을 막기 위한 방법\n",
    "# 학습시에는 랜덤하게 뉴런을 끄지만 , 평가모드로 전환되면 모든 뉴런을 사용\n",
    "# alexnet(x_test) : 예측하는것. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d1e4989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 합성곱 연산 -> 이미지의 특징을 추출\n",
    "# convolution(합성곱) - CNN\n",
    "# 28(높이) 28(너비) 39(깊이)  ->  3차원 tensor \n",
    "# 일반적으로 커널은 3 x 3 or 5 x 5 많이 사용함\n",
    "# 5 X 5 이미지가 있고 커널이 3 x 3일때 하나씩 출력하는 것. 2를 뺴면 됌ㅋ\n",
    "# 패딩을 주면 원본크가가 유지가 됨 / 패딩을 주지 않으면 이미지가 줄어듬.\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4e48e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텐서의 크기 : torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn # 신경망을 구성하는 역할 : nn\n",
    "\n",
    "# CNN을 구할때 배치크기 x 채널크기 x 높이 x 너비\n",
    "# torch는 채널이 앞에 있음 (tensorflow는 채널이 뒤에 있음 )\n",
    "\n",
    "inputs = torch.Tensor(1,1,28,28) # 채널 1개 28x28 크기를 갖는 1개의 흑백이미지 \n",
    "print(f'텐서의 크기 : {inputs.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2764a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "# 합성곱 층과 폴링\n",
    "conv1 = nn.Conv2d(1,32,3,padding=1) # 차례대로 채널 , 입력 , 커널사이즈 / 얘가 출력하는 것은 특성맵임. strid=1 padding=1  28,28,32\n",
    "print(conv1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a2c753a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "# 2번째 합성곱 층\n",
    "conv2 = nn.Conv2d(32,64,3,padding=1)\n",
    "print(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c2875e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "pool = nn.MaxPool2d(2) #2x2\n",
    "print(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e75071ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 28, 28])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 통과하기\n",
    "inputs.size() # 샘플1개 , 채널1개 , 28사이즈\n",
    "out = conv1(inputs)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3007cc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "out = pool(out) # pool은 2바이2\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a5ffd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "out = conv2(out)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0bb0df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "out = pool(out)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa5fedf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size(0) # 0번째 차원 숫자에 따라 차원이 출력됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "617b9baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.4329, -0.0564, -0.0564,  ..., -0.0713, -0.0713, -0.0622]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.view(out.size(0),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aff70c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3136])\n"
     ]
    }
   ],
   "source": [
    "out = out.view(out.size(0),-1)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86be1942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "fc = nn.Linear(3136,10)\n",
    "out = fc(out)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9301f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "434249b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C , H , W\n",
    "\n",
    "transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5 , ) , (0.5 , ))] )\n",
    "# 모든데이터에 평균이 0.5 표준편차가 0.5 되게 설정\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data' , train = True , download=True , transform=transform)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data' , train = False , download=True , transform=transform)\n",
    "\n",
    "train_load = DataLoader(train_dataset , batch_size=64 , shuffle=True)\n",
    "test_load = DataLoader(test_dataset , batch_size=64 , shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17027f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 채널 정보 확인\n",
    "for data in train_dataset:\n",
    "    print(data[0].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dca8c9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#loader에 있는 정보 보기 -> 64개 데이터의 1, 28,28\n",
    "for data in train_load:\n",
    "    print(data[0].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f932ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN , self).__init__()  # 64 1 28 28\n",
    "        self.conv1 = nn.Conv2d(1,32,3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(32,64,3,padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear( 64*7*7 ,128 )\n",
    "        self.fc2 = nn.Linear(128 , 10) #은닉층\n",
    "    def forward(self ,  x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) # (64 1 28 28) 패딩을 줬기때문에 값 그대로  -> (64 32 14 14)\n",
    "        x = self.pool(F.relu(self.conv2(x))) # (64 32 14 14)  -> (64 64 7 7)\n",
    "        x = x.view(x.size(0) , -1)\n",
    "        x = F.relu(self.fc1(x)) # Error : 64x1568 and 3136x128\n",
    "        out = self.fc2(x)\n",
    "        return out\n",
    "\n",
    "model = CNN()\n",
    "model\n",
    "\n",
    "device = torch.device('cuda'  if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() #손실함수 설정해줘야함 /  손실함수는 내부에 소프트맥스 + 로그 손실 계산함 ( 다중 클래스 )\n",
    "optimizer = optim.Adam(model.parameters() , lr = 0.001)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44a18bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_load) #데이터 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35eb4765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 / 5 , loss : 0.4379\n",
      "Epoch : 2 / 5 , loss : 0.2801\n",
      "Epoch : 3 / 5 , loss : 0.2351\n",
      "Epoch : 4 / 5 , loss : 0.2012\n",
      "Epoch : 5 / 5 , loss : 0.1762\n"
     ]
    }
   ],
   "source": [
    "# 훈련 루프\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() # dropout이나 배치nomal 기능성 레이어(층)을 활성화 시킴\n",
    "    # 손실률은 계속 계산해야하기떄문에 하기 코드작성\n",
    "    runing_loss = 0.0\n",
    "    for inputs , labels in train_load:\n",
    "        inputs , labels = inputs.to(device) , labels.to(device)    \n",
    "        optimizer.zero_grad() # 그레디언트 초기화\n",
    "        outputs = model(inputs) #forward 호출하여 예측한다.\n",
    "        loss = criterion(outputs , labels) # 손실계산\n",
    "        loss.backward() #역전파(그레이던트(기울기) 계산 -> 자동미분)\n",
    "        optimizer.step() # 역전파가 적용 / 위로 타고 올라가면서 파라메터(가중치)를 업데이트시켜줌\n",
    "        runing_loss += loss.item()\n",
    "    print(f'Epoch : {epoch+1} / {num_epochs} , loss : {runing_loss / len(train_load):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98466352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.9154\n"
     ]
    }
   ],
   "source": [
    "# 평가모드로 변환 정규화하는애들은 학습할떄 전체 데이터로 하기위해\n",
    "model.eval() #평가모드\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs , labels in test_load:\n",
    "        inputs , labels = inputs.to(device) , labels.to(device)\n",
    "        output = model(inputs)\n",
    "        _, predicted = torch.max(output.data , 1) # 최대 확률 클래스 예측\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print(f'test accuracy : {correct / total}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d22b0b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = next(iter(test_load))[0].size()\n",
    "# torch.max(model(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2822d966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([9, 2, 1, 1, 6]),\n",
       " tensor([9, 2, 1, 1, 6]),\n",
       " tensor([0, 7, 7, 8, 5]),\n",
       " tensor([0, 7, 7, 8, 5]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X , y = next(iter(test_load))\n",
    "_, predicted = torch.max(model(X),1)\n",
    "predicted[:5] , y[:5] , predicted[-5:] , y[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d1b1cd",
   "metadata": {},
   "source": [
    "### 3차원 컬러 이미지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0677a3f0",
   "metadata": {},
   "source": [
    "#### RGB 체널의 각각의 평균과 표준편차"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d00722b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4914, 0.4822, 0.4465])\n",
      "tensor([0.2023, 0.1994, 0.2010])\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose( [transforms.ToTensor()] )\n",
    "\n",
    "test = torchvision.datasets.CIFAR10(root='./data' , train = True ,\n",
    "                                             download=True , transform=transform)\n",
    "\n",
    "\n",
    "mean = torch.zeros(3)\n",
    "std = torch.zeros(3)\n",
    "for data , _ in test:\n",
    "    mean += data.mean(dim=(1,2))\n",
    "    std += data.std(dim=(1,2))\n",
    "    # print(data[0].size())\n",
    "    # print(data[0].mean())# tensor의 평균\n",
    "    # print(data[0].mean(dim=(1,2))) # RGB 평균\n",
    "    # print(data[0])\n",
    "print(mean / len(test))\n",
    "print(std / len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d144fc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4914008 , 0.482159  , 0.44653094], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean / len(test)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cb60bd",
   "metadata": {},
   "source": [
    "#### 학습 / 검증 / 테스트 데이터 로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "056aa96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rgb_mean = mean / len(test)\n",
    "rgb_std = std / len(test)\n",
    "transform = transforms.Compose( [transforms.ToTensor(),\n",
    "                                 transforms.Normalize(rgb_mean , rgb_std)] )\n",
    "\n",
    "full_train_dataset = torchvision.datasets.CIFAR10(root='./data' , train = True ,\n",
    "                                             download=True , transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data' , train = False ,\n",
    "                                            download=True , transform=transform)\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "# train/val 분할 : 8:2\n",
    "train_size = int(len(full_train_dataset)*0.8)\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "train_dataset , val_dataset = random_split(full_train_dataset , [train_size , val_size])\n",
    "\n",
    "\n",
    "\n",
    "train_load = DataLoader(train_dataset , batch_size=64 , shuffle=True)\n",
    "val_load = DataLoader(val_dataset , batch_size=64 , shuffle=False)\n",
    "test_load = DataLoader(test_dataset , batch_size=64 , shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72496fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))[0].size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a7ce52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "for data in train_load:\n",
    "    print(data[0].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d02e375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 32, 32])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b84223",
   "metadata": {},
   "source": [
    "#### 컬러이미지 처리 CNN 모델을 구현\n",
    "- 손실함수\n",
    "- 옵티마이져\n",
    "- 스케줄러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d39e4425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델클래스\n",
    "# 손실함수\n",
    "# 역전파를 위한 optimizer\n",
    "# 학습루프\n",
    "# 평가\n",
    "# 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "efb3699d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj (instance of CNN_CIFAR10) is not an instance or subtype of type (CNN).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m model = CNN()\n\u001b[32m     18\u001b[39m model\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m cnn_cifar10_model = \u001b[43mCNN_CIFAR10\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m device = torch.device(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m  \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mcpu\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     22\u001b[39m model.to(device)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mCNN_CIFAR10.__init__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mCNN\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m()  \u001b[38;5;66;03m# 64, 3, 32, 32\u001b[39;00m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mself\u001b[39m.conv1 = nn.Conv2d(\u001b[32m3\u001b[39m,\u001b[32m32\u001b[39m,\u001b[32m3\u001b[39m,padding=\u001b[32m1\u001b[39m)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mself\u001b[39m.conv2 = nn.Conv2d(\u001b[32m32\u001b[39m,\u001b[32m64\u001b[39m,\u001b[32m3\u001b[39m,padding=\u001b[32m1\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: super(type, obj): obj (instance of CNN_CIFAR10) is not an instance or subtype of type (CNN)."
     ]
    }
   ],
   "source": [
    "class CNN_CIFAR10(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN , self).__init__()  # 64, 3, 32, 32\n",
    "        self.conv1 = nn.Conv2d(3,32,3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(32,64,3,padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear( 64*8*8 ,128 )\n",
    "        self.fc2 = nn.Linear(128 , 10) #은닉층\n",
    "    def forward(self ,  x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) # (64, 3, 32, 32)  ->  (64, 32, 16, 16)\n",
    "        x = self.pool(F.relu(self.conv2(x))) # (64, 32, 16, 16) -> (64, 64, 8, 8)\n",
    "        x = x.view(x.size(0) , -1)\n",
    "        x = F.relu(self.fc1(x)) \n",
    "        out = self.fc2(x)\n",
    "        return out\n",
    "\n",
    "model = CNN()\n",
    "model\n",
    "\n",
    "cnn_cifar10_model = CNN_CIFAR10()\n",
    "device = torch.device('cuda'  if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_cifar10_model.parameters() , lr = 0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer , step_size=7 , gamma=0.1) #gamma : 매번 학습할떄마다(7epoch) lr*0.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1a37d6",
   "metadata": {},
   "source": [
    "#### EarlyStopping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ccbfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self , patience = 5 , min_delta = 0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.count = 0\n",
    "        self.best_loss = float('inf')\n",
    "    def __call__(self , val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True # 조기 종류\n",
    "        return False\n",
    "early_stopping = EarlyStopping()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c1df9a",
   "metadata": {},
   "source": [
    "#### 훈련 / 검증 함수 (accuracy 포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7940fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader , criterion , optimizer , device):\n",
    "    model.train() # dropout이나 배치nomal 기능성 레이어(층)을 활성화 시킴\n",
    "    # 손실률은 계속 계산해야하기떄문에 하기 코드작성\n",
    "    runing_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    iterator = tqdm(enumerate(loader),total = len(loader) , desc='Train')\n",
    "    for batch_idx , (inputs , labels) in iterator:\n",
    "        inputs , labels = inputs.to(device) , labels.to(device)    \n",
    "        optimizer.zero_grad() # 그레디언트 초기화\n",
    "        outputs = model(inputs) # 순전파 forward 호출 --> 예측\n",
    "        loss = criterion(outputs , labels) # 손실계산\n",
    "        loss.backward() #역전파(그레이던트(기울기) 계산 -> 자동미분)\n",
    "        optimizer.step() # 역전파가 적용 / 위로 타고 올라가면서 파라메터(가중치)를 업데이트시켜줌\n",
    "        runing_loss += loss.item()\n",
    "\n",
    "        _ , predicted = torch.max(outputs.data,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()  #CPU로 계싼그래프에서 빠짐. (device GPU에서 함)\n",
    "        iterator.set_postfix({'loss' : f'{loss.item():.3f}' , 'acc': f'{correct/total:.3f}'})\n",
    "    avg_loss = runing_loss / len(loader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss , accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f721fb",
   "metadata": {},
   "source": [
    "#### 훈련루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0448d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 루프\n",
    "num_epochs = 20\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc =  train_epoch(cnn_cifar10_model,train_load,criterion,optimizer,device)\n",
    "    scheduler.step() # 스케줄러 업데이트\n",
    "    \n",
    "    # early stoppin check\n",
    "    if early_stopping(best_val_loss):\n",
    "        print(f'Early Stopping epoch : {epoch+1}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc02c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f593518",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.1 < float('inf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
