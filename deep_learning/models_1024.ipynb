{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aed0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.13/site-packages (2.9.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.13/site-packages (0.24.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/anaconda3/lib/python3.13/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.13/site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.13/site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13457b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.0 0.24.0\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision\n",
    "print(torch.__version__, torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50a22eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models # ì´ë¯¸ ë§Œë“¤ì–´ì§„ ìœ ëª…í•œ ë”¥ëŸ¬ë‹ ëª¨ë¸ë“¤â€ì„ ë¶ˆëŸ¬ì˜¤ëŠ” êµ¬ë¬¸ì´ì•¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14741d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AlexNet',\n",
       " 'AlexNet_Weights',\n",
       " 'ConvNeXt',\n",
       " 'ConvNeXt_Base_Weights',\n",
       " 'ConvNeXt_Large_Weights',\n",
       " 'ConvNeXt_Small_Weights',\n",
       " 'ConvNeXt_Tiny_Weights',\n",
       " 'DenseNet',\n",
       " 'DenseNet121_Weights',\n",
       " 'DenseNet161_Weights',\n",
       " 'DenseNet169_Weights',\n",
       " 'DenseNet201_Weights',\n",
       " 'EfficientNet',\n",
       " 'EfficientNet_B0_Weights',\n",
       " 'EfficientNet_B1_Weights',\n",
       " 'EfficientNet_B2_Weights',\n",
       " 'EfficientNet_B3_Weights',\n",
       " 'EfficientNet_B4_Weights',\n",
       " 'EfficientNet_B5_Weights',\n",
       " 'EfficientNet_B6_Weights',\n",
       " 'EfficientNet_B7_Weights',\n",
       " 'EfficientNet_V2_L_Weights',\n",
       " 'EfficientNet_V2_M_Weights',\n",
       " 'EfficientNet_V2_S_Weights',\n",
       " 'GoogLeNet',\n",
       " 'GoogLeNetOutputs',\n",
       " 'GoogLeNet_Weights',\n",
       " 'Inception3',\n",
       " 'InceptionOutputs',\n",
       " 'Inception_V3_Weights',\n",
       " 'MNASNet',\n",
       " 'MNASNet0_5_Weights',\n",
       " 'MNASNet0_75_Weights',\n",
       " 'MNASNet1_0_Weights',\n",
       " 'MNASNet1_3_Weights',\n",
       " 'MaxVit',\n",
       " 'MaxVit_T_Weights',\n",
       " 'MobileNetV2',\n",
       " 'MobileNetV3',\n",
       " 'MobileNet_V2_Weights',\n",
       " 'MobileNet_V3_Large_Weights',\n",
       " 'MobileNet_V3_Small_Weights',\n",
       " 'RegNet',\n",
       " 'RegNet_X_16GF_Weights',\n",
       " 'RegNet_X_1_6GF_Weights',\n",
       " 'RegNet_X_32GF_Weights',\n",
       " 'RegNet_X_3_2GF_Weights',\n",
       " 'RegNet_X_400MF_Weights',\n",
       " 'RegNet_X_800MF_Weights',\n",
       " 'RegNet_X_8GF_Weights',\n",
       " 'RegNet_Y_128GF_Weights',\n",
       " 'RegNet_Y_16GF_Weights',\n",
       " 'RegNet_Y_1_6GF_Weights',\n",
       " 'RegNet_Y_32GF_Weights',\n",
       " 'RegNet_Y_3_2GF_Weights',\n",
       " 'RegNet_Y_400MF_Weights',\n",
       " 'RegNet_Y_800MF_Weights',\n",
       " 'RegNet_Y_8GF_Weights',\n",
       " 'ResNeXt101_32X8D_Weights',\n",
       " 'ResNeXt101_64X4D_Weights',\n",
       " 'ResNeXt50_32X4D_Weights',\n",
       " 'ResNet',\n",
       " 'ResNet101_Weights',\n",
       " 'ResNet152_Weights',\n",
       " 'ResNet18_Weights',\n",
       " 'ResNet34_Weights',\n",
       " 'ResNet50_Weights',\n",
       " 'ShuffleNetV2',\n",
       " 'ShuffleNet_V2_X0_5_Weights',\n",
       " 'ShuffleNet_V2_X1_0_Weights',\n",
       " 'ShuffleNet_V2_X1_5_Weights',\n",
       " 'ShuffleNet_V2_X2_0_Weights',\n",
       " 'SqueezeNet',\n",
       " 'SqueezeNet1_0_Weights',\n",
       " 'SqueezeNet1_1_Weights',\n",
       " 'SwinTransformer',\n",
       " 'Swin_B_Weights',\n",
       " 'Swin_S_Weights',\n",
       " 'Swin_T_Weights',\n",
       " 'Swin_V2_B_Weights',\n",
       " 'Swin_V2_S_Weights',\n",
       " 'Swin_V2_T_Weights',\n",
       " 'VGG',\n",
       " 'VGG11_BN_Weights',\n",
       " 'VGG11_Weights',\n",
       " 'VGG13_BN_Weights',\n",
       " 'VGG13_Weights',\n",
       " 'VGG16_BN_Weights',\n",
       " 'VGG16_Weights',\n",
       " 'VGG19_BN_Weights',\n",
       " 'VGG19_Weights',\n",
       " 'ViT_B_16_Weights',\n",
       " 'ViT_B_32_Weights',\n",
       " 'ViT_H_14_Weights',\n",
       " 'ViT_L_16_Weights',\n",
       " 'ViT_L_32_Weights',\n",
       " 'VisionTransformer',\n",
       " 'Weights',\n",
       " 'WeightsEnum',\n",
       " 'Wide_ResNet101_2_Weights',\n",
       " 'Wide_ResNet50_2_Weights',\n",
       " '_GoogLeNetOutputs',\n",
       " '_InceptionOutputs',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_api',\n",
       " '_meta',\n",
       " '_utils',\n",
       " 'alexnet',\n",
       " 'convnext',\n",
       " 'convnext_base',\n",
       " 'convnext_large',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'densenet',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'detection',\n",
       " 'efficientnet',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_b5',\n",
       " 'efficientnet_b6',\n",
       " 'efficientnet_b7',\n",
       " 'efficientnet_v2_l',\n",
       " 'efficientnet_v2_m',\n",
       " 'efficientnet_v2_s',\n",
       " 'get_model',\n",
       " 'get_model_builder',\n",
       " 'get_model_weights',\n",
       " 'get_weight',\n",
       " 'googlenet',\n",
       " 'inception',\n",
       " 'inception_v3',\n",
       " 'list_models',\n",
       " 'maxvit',\n",
       " 'maxvit_t',\n",
       " 'mnasnet',\n",
       " 'mnasnet0_5',\n",
       " 'mnasnet0_75',\n",
       " 'mnasnet1_0',\n",
       " 'mnasnet1_3',\n",
       " 'mobilenet',\n",
       " 'mobilenet_v2',\n",
       " 'mobilenet_v3_large',\n",
       " 'mobilenet_v3_small',\n",
       " 'mobilenetv2',\n",
       " 'mobilenetv3',\n",
       " 'optical_flow',\n",
       " 'quantization',\n",
       " 'regnet',\n",
       " 'regnet_x_16gf',\n",
       " 'regnet_x_1_6gf',\n",
       " 'regnet_x_32gf',\n",
       " 'regnet_x_3_2gf',\n",
       " 'regnet_x_400mf',\n",
       " 'regnet_x_800mf',\n",
       " 'regnet_x_8gf',\n",
       " 'regnet_y_128gf',\n",
       " 'regnet_y_16gf',\n",
       " 'regnet_y_1_6gf',\n",
       " 'regnet_y_32gf',\n",
       " 'regnet_y_3_2gf',\n",
       " 'regnet_y_400mf',\n",
       " 'regnet_y_800mf',\n",
       " 'regnet_y_8gf',\n",
       " 'resnet',\n",
       " 'resnet101',\n",
       " 'resnet152',\n",
       " 'resnet18',\n",
       " 'resnet34',\n",
       " 'resnet50',\n",
       " 'resnext101_32x8d',\n",
       " 'resnext101_64x4d',\n",
       " 'resnext50_32x4d',\n",
       " 'segmentation',\n",
       " 'shufflenet_v2_x0_5',\n",
       " 'shufflenet_v2_x1_0',\n",
       " 'shufflenet_v2_x1_5',\n",
       " 'shufflenet_v2_x2_0',\n",
       " 'shufflenetv2',\n",
       " 'squeezenet',\n",
       " 'squeezenet1_0',\n",
       " 'squeezenet1_1',\n",
       " 'swin_b',\n",
       " 'swin_s',\n",
       " 'swin_t',\n",
       " 'swin_transformer',\n",
       " 'swin_v2_b',\n",
       " 'swin_v2_s',\n",
       " 'swin_v2_t',\n",
       " 'vgg',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'video',\n",
       " 'vision_transformer',\n",
       " 'vit_b_16',\n",
       " 'vit_b_32',\n",
       " 'vit_h_14',\n",
       " 'vit_l_16',\n",
       " 'vit_l_32',\n",
       " 'wide_resnet101_2',\n",
       " 'wide_resnet50_2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(models) # ì§€ê¸ˆ ë¶ˆëŸ¬ì˜¨ models ì•ˆì— ë­ê°€ ë“¤ì–´ ìˆëŠ”ì§€ ë³´ì—¬ì¤˜!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1d71c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "alexnet = models.AlexNet()\n",
    "print(alexnet)\n",
    "# 2012ë…„ ì´ë¯¸ì§€ ì¸ì‹ í˜ëª… ì¼ìœ¼í‚¨ CNN ëª¨ë¸ -> CNN:ì´ë¯¸ì§€â€™ë¥¼ ë³´ê³  ì´í•´í•  ìˆ˜ ìˆë„ë¡ ë§Œë“¤ì–´ì§„ ë”¥ëŸ¬ë‹ ëª¨ë¸\n",
    "# CNNì€ ë³´í†µ ì´ë ‡ê²Œ êµ¬ì„±ë¼:\n",
    "# Convolution ì¸µ (Conv2d) â†’ íŠ¹ì§•ì„ ì¶”ì¶œ\n",
    "# ReLU ì¸µ â†’ ìŒìˆ˜ ì—†ì• ê³  í™œì„±í™”\n",
    "# Pooling ì¸µ (MaxPool2d) â†’ ì¤‘ìš”í•œ ì •ë³´ë§Œ ë‚¨ê¸°ê¸°\n",
    "# Flatten â†’ Fully Connected(Linear) â†’ ë¶„ë¥˜ ê²°ê³¼ ì¶œë ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "657a8d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í™œì„±í™” í•¨ìˆ˜\n",
    "# Relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f09d5b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet-101 : Residual Network(ì”ì°¨ ì‹ ê²½ë§)â€ì˜ ì¤„ì„ë§\n",
    "# ê¹Šì–´ì§ˆìˆ˜ë¡ ì›ë˜ëŠ” í•™ìŠµì´ ì–´ë ¤ì›Œì§€ëŠ”ë°, ResNetì€ íŠ¹ë³„í•œ ì§€ë¦„ê¸¸ë¡œ ì´ ë¬¸ì œë¥¼ í•´ê²°\n",
    "# ê·¸ ì§€ë¦„ê¸¸ì˜ ì´ë¦„ì€ (ìŠ¤í‚µì»¤ë„¥ì…˜ (Skip Connection , Residual Block))\n",
    "# ì´ ì§€ë¦„ê¸¸ì„ í¬í•¨í•œ ì‘ì€ ë¬¶ìŒì„ Residual Block(ì”ì°¨ ë¸”ë¡) ì´ë¼ê³  ë¶ˆëŸ¬.\n",
    "# Skip Connection - â€œì™„ì „íˆ ìƒˆë¡œìš´ ê±¸ ë‹¤â€ ê°€ ì•„ë‹ˆë¼ ê¸°ì¡´ í–‰ë™ê³¼ì˜ ì°¨ì´ë§Œ ë°°ìš°ê²Œ í•˜ëŠ” ê±°ì•¼.\n",
    "# W, xë¥¼ ì§ì ‘ ë‹¤ í•™ìŠµí•˜ëŠ” ëŒ€ì‹  ğ‘“(ğ‘¥)f(x) = ì”ì°¨(residual)ë§Œ í•™ìŠµ\n",
    "# ì´ˆê¸°xì˜ ê°’ì´ ì§€ë¦„ê¸¸ì„ í†µí•´ ë’¤ìª½ ë ˆì´ì–´ê¹Œì§€ ì§ì ‘ ì „ë‹¬\n",
    "# ê¹Šì€ ì‹ ê²½ë§ì€ ì—­ì „íŒŒí•  ë•Œ ê¸°ìš¸ê¸°(gradient) ê°€ ì ì  ì‘ì•„ì ¸ì„œ ì†Œì‹¤ë˜ê¸° ì‰½ë‹¤.\n",
    "# ìŠ¤í‚µ ì»¤ë„¥ì…˜ì´ ìˆìœ¼ë©´, ì—­ì „íŒŒí•  ë•Œ ê¸°ìš¸ê¸°ê°€ ì§€ë¦„ê¸¸ì„ í†µí•´ â€˜ì§ì ‘â€™ ì´ˆë°˜ì¸µê¹Œì§€ ì „ë‹¬ëœë‹¤.\n",
    "# ë ˆì´ì–´ê°€ 100ì¸µ ë„˜ìœ¼ë©´ ì†Œì‹¤/í­ë°œì´ í•„ì—°ì  â†’ ResNetì€ ì´ê±¸ í•´ê²° -> ë” ê¹Šì€ ì¸µì„ ë³¼ ìˆ˜ ìˆê²Œ ë¨\n",
    "# H(x) = F(x) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6620de68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = models.resnet101(pretrained = False)\n",
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e646c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "# PIL : íŒŒì´ì¬ì—ê²Œ ì‚¬ì§„ì„ ì—´ê³ , ìë¥´ê³ , ì €ì¥í•˜ê³ , ë°”ê¾¸ëŠ” ëŠ¥ë ¥ì„ ì£¼ëŠ” ë„êµ¬ ì„¸íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2916117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alexnet.eval() ëª¨ë¸ì„ í‰ê°€í• ë•Œ í‰ê°€ëª¨ë“œë¡œ ì „í™˜í•˜ëŠ” ê²ƒ - ì´ì œ ê³µë¶€ ê·¸ë§Œ, ì‹œí—˜ ë³´ì!\n",
    "# PyTorchì—ì„œëŠ” ëª¨ë¸ì„ ë‘ ê°€ì§€ ëª¨ë“œë¡œ ë‚˜ëˆ ì„œ ë™ì‘ì‹œì¼œ\n",
    "# 1) í•™ìŠµ ëª¨ë“œ (training mode) - model.train() / 2) í‰ê°€ ëª¨ë“œ (evaluation mode) - model.eval()\n",
    "# ë°°ì¹˜ì •ê·œí™” : í›ˆë ¨í•  ë•Œì˜ ê²½í—˜(í†µê³„)â€ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•´ì„œ ì˜ˆì¸¡ì„ ì•ˆì •í™”ì‹œí‚¤ëŠ” ê±°ì•¼.\n",
    "# í•™ìŠµì„ ì•ˆì •ì ìœ¼ë¡œâ€ í•˜ê²Œ ë„ì™€ì£¼ëŠ” ì¸µìœ¼ë¡œ í›ˆë ¨í•  ë•ŒëŠ” ê° ë¯¸ë‹ˆë°°ì¹˜(batch) ë§ˆë‹¤\n",
    "# í‰ê· (mean)ê³¼ ë¶„ì‚°(variance)ì„ ì¦‰ì„ ê³„ì‚°í•´ì„œ ì‚¬ìš©í•´\n",
    "# í•˜ì§€ë§Œ í‰ê°€í•  ë•ŒëŠ”,â€œì „ì²´ ë°ì´í„°ì—ì„œ í‰ê· ì ìœ¼ë¡œ ì–´ë–¤ ê°’ì´ì—ˆëŠ”ì§€â€ë¥¼ ì‚¬ìš©í•´ì•¼ ì•ˆì •ì ì´ì§€!\n",
    "# ë“œëì•„ì›ƒ : ì´ê±´ í•™ìŠµ ì¤‘ì— ê³¼ì í•©(ì™¸ì›Œë²„ë¦¬ëŠ” ë¬¸ì œ) ì„ ë§‰ê¸° ìœ„í•œ ë°©ë²•\n",
    "# í•™ìŠµì‹œì—ëŠ” ëœë¤í•˜ê²Œ ë‰´ëŸ°ì„ ë„ì§€ë§Œ , í‰ê°€ëª¨ë“œë¡œ ì „í™˜ë˜ë©´ ëª¨ë“  ë‰´ëŸ°ì„ ì‚¬ìš©\n",
    "# alexnet(x_test) : ì˜ˆì¸¡í•˜ëŠ”ê²ƒ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d1e4989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•©ì„±ê³± ì—°ì‚° -> ì´ë¯¸ì§€ì˜ íŠ¹ì§•ì„ ì¶”ì¶œ\n",
    "# convolution(í•©ì„±ê³±) - CNN\n",
    "# 28(ë†’ì´) 28(ë„ˆë¹„) 39(ê¹Šì´)  ->  3ì°¨ì› tensor \n",
    "# ì¼ë°˜ì ìœ¼ë¡œ ì»¤ë„ì€ 3 x 3 or 5 x 5 ë§ì´ ì‚¬ìš©í•¨\n",
    "# 5 X 5 ì´ë¯¸ì§€ê°€ ìˆê³  ì»¤ë„ì´ 3 x 3ì¼ë•Œ í•˜ë‚˜ì”© ì¶œë ¥í•˜ëŠ” ê²ƒ. 2ë¥¼ ëº´ë©´ ëŒã…‹\n",
    "# íŒ¨ë”©ì„ ì£¼ë©´ ì›ë³¸í¬ê°€ê°€ ìœ ì§€ê°€ ë¨ / íŒ¨ë”©ì„ ì£¼ì§€ ì•Šìœ¼ë©´ ì´ë¯¸ì§€ê°€ ì¤„ì–´ë“¬.\n",
    "# \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4e48e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í…ì„œì˜ í¬ê¸° : torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn # ì‹ ê²½ë§ì„ êµ¬ì„±í•˜ëŠ” ì—­í•  : nn\n",
    "\n",
    "# CNNì„ êµ¬í• ë•Œ ë°°ì¹˜í¬ê¸° x ì±„ë„í¬ê¸° x ë†’ì´ x ë„ˆë¹„\n",
    "# torchëŠ” ì±„ë„ì´ ì•ì— ìˆìŒ (tensorflowëŠ” ì±„ë„ì´ ë’¤ì— ìˆìŒ )\n",
    "\n",
    "inputs = torch.Tensor(1,1,28,28) # ì±„ë„ 1ê°œ 28x28 í¬ê¸°ë¥¼ ê°–ëŠ” 1ê°œì˜ í‘ë°±ì´ë¯¸ì§€ \n",
    "print(f'í…ì„œì˜ í¬ê¸° : {inputs.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2764a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "# í•©ì„±ê³± ì¸µê³¼ í´ë§\n",
    "conv1 = nn.Conv2d(1,32,3,padding=1) # ì°¨ë¡€ëŒ€ë¡œ ì±„ë„ , ì…ë ¥ , ì»¤ë„ì‚¬ì´ì¦ˆ / ì–˜ê°€ ì¶œë ¥í•˜ëŠ” ê²ƒì€ íŠ¹ì„±ë§µì„. strid=1 padding=1  28,28,32\n",
    "print(conv1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a2c753a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "# 2ë²ˆì§¸ í•©ì„±ê³± ì¸µ\n",
    "conv2 = nn.Conv2d(32,64,3,padding=1)\n",
    "print(conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c2875e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "pool = nn.MaxPool2d(2) #2x2\n",
    "print(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e75071ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 28, 28])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ë°ì´í„° í†µê³¼í•˜ê¸°\n",
    "inputs.size() # ìƒ˜í”Œ1ê°œ , ì±„ë„1ê°œ , 28ì‚¬ì´ì¦ˆ\n",
    "out = conv1(inputs)\n",
    "out.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3007cc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "out = pool(out) # poolì€ 2ë°”ì´2\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a5ffd4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "out = conv2(out)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0bb0df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "out = pool(out)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa5fedf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.size(0) # 0ë²ˆì§¸ ì°¨ì› ìˆ«ìì— ë”°ë¼ ì°¨ì›ì´ ì¶œë ¥ë¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "617b9baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.8448e-02,  3.0936e-02,  3.0936e-02,  ..., -2.2457e+25,\n",
       "         -9.5736e-02, -2.7887e-02]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.view(out.size(0),-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aff70c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3136])\n"
     ]
    }
   ],
   "source": [
    "out = out.view(out.size(0),-1)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "86be1942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "fc = nn.Linear(3136,10)\n",
    "out = fc(out)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b9301f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "434249b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C , H , W\n",
    "\n",
    "transform = transforms.Compose( [transforms.ToTensor(), transforms.Normalize((0.5 , ) , (0.5 , ))] )\n",
    "# ëª¨ë“ ë°ì´í„°ì— í‰ê· ì´ 0.5 í‘œì¤€í¸ì°¨ê°€ 0.5 ë˜ê²Œ ì„¤ì •\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data' , train = True , download=True , transform=transform)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data' , train = False , download=True , transform=transform)\n",
    "\n",
    "train_load = DataLoader(train_dataset , batch_size=64 , shuffle=True)\n",
    "test_load = DataLoader(test_dataset , batch_size=64 , shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17027f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# ì±„ë„ ì •ë³´ í™•ì¸\n",
    "for data in train_dataset:\n",
    "    print(data[0].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dca8c9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#loaderì— ìˆëŠ” ì •ë³´ ë³´ê¸° -> 64ê°œ ë°ì´í„°ì˜ 1, 28,28\n",
    "for data in train_load:\n",
    "    print(data[0].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f932ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN , self).__init__()  # 64 1 28 28\n",
    "        self.conv1 = nn.Conv2d(1,32,3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(32,64,3,padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear( 64*7*7 ,128 )\n",
    "        self.fc2 = nn.Linear(128 , 10) #ì€ë‹‰ì¸µ\n",
    "    def forward(self ,  x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) # (64 1 28 28) íŒ¨ë”©ì„ ì¤¬ê¸°ë•Œë¬¸ì— ê°’ ê·¸ëŒ€ë¡œ  -> (64 32 14 14)\n",
    "        x = self.pool(F.relu(self.conv2(x))) # (64 32 14 14)  -> (64 64 7 7)\n",
    "        x = x.view(x.size(0) , -1)\n",
    "        x = F.relu(self.fc1(x)) # Error : 64x1568 and 3136x128\n",
    "        out = self.fc2(x)\n",
    "        return out\n",
    "\n",
    "model = CNN()\n",
    "model\n",
    "\n",
    "device = torch.device('cuda'  if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() #ì†ì‹¤í•¨ìˆ˜ ì„¤ì •í•´ì¤˜ì•¼í•¨ /  ì†ì‹¤í•¨ìˆ˜ëŠ” ë‚´ë¶€ì— ì†Œí”„íŠ¸ë§¥ìŠ¤ + ë¡œê·¸ ì†ì‹¤ ê³„ì‚°í•¨ ( ë‹¤ì¤‘ í´ë˜ìŠ¤ )\n",
    "optimizer = optim.Adam(model.parameters() , lr = 0.001)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "44a18bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "938"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_load) #ë°ì´í„° ê°œìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35eb4765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 / 5 , loss : 0.4306\n",
      "Epoch : 2 / 5 , loss : 0.2731\n",
      "Epoch : 3 / 5 , loss : 0.2283\n",
      "Epoch : 4 / 5 , loss : 0.1977\n",
      "Epoch : 5 / 5 , loss : 0.1698\n"
     ]
    }
   ],
   "source": [
    "# í›ˆë ¨ ë£¨í”„\n",
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() # dropoutì´ë‚˜ ë°°ì¹˜nomal ê¸°ëŠ¥ì„± ë ˆì´ì–´(ì¸µ)ì„ í™œì„±í™” ì‹œí‚´\n",
    "    # ì†ì‹¤ë¥ ì€ ê³„ì† ê³„ì‚°í•´ì•¼í•˜ê¸°ë–„ë¬¸ì— í•˜ê¸° ì½”ë“œì‘ì„±\n",
    "    runing_loss = 0.0\n",
    "    for inputs , labels in train_load:\n",
    "        inputs , labels = inputs.to(device) , labels.to(device)    \n",
    "        optimizer.zero_grad() # ê·¸ë ˆë””ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "        outputs = model(inputs) #forward í˜¸ì¶œí•˜ì—¬ ì˜ˆì¸¡í•œë‹¤.\n",
    "        loss = criterion(outputs , labels) # ì†ì‹¤ê³„ì‚°\n",
    "        loss.backward() #ì—­ì „íŒŒ(ê·¸ë ˆì´ë˜íŠ¸(ê¸°ìš¸ê¸°) ê³„ì‚° -> ìë™ë¯¸ë¶„)\n",
    "        optimizer.step() # ì—­ì „íŒŒê°€ ì ìš© / ìœ„ë¡œ íƒ€ê³  ì˜¬ë¼ê°€ë©´ì„œ íŒŒë¼ë©”í„°(ê°€ì¤‘ì¹˜)ë¥¼ ì—…ë°ì´íŠ¸ì‹œì¼œì¤Œ\n",
    "        runing_loss += loss.item()\n",
    "    print(f'Epoch : {epoch+1} / {num_epochs} , loss : {runing_loss / len(train_load):.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98466352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.9191\n"
     ]
    }
   ],
   "source": [
    "# í‰ê°€ëª¨ë“œë¡œ ë³€í™˜ ì •ê·œí™”í•˜ëŠ”ì• ë“¤ì€ í•™ìŠµí• ë–„ ì „ì²´ ë°ì´í„°ë¡œ í•˜ê¸°ìœ„í•´\n",
    "model.eval() #í‰ê°€ëª¨ë“œ\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs , labels in test_load:\n",
    "        inputs , labels = inputs.to(device) , labels.to(device)\n",
    "        output = model(inputs)\n",
    "        _, predicted = torch.max(output.data , 1) # ìµœëŒ€ í™•ë¥  í´ë˜ìŠ¤ ì˜ˆì¸¡\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print(f'test accuracy : {correct / total}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d22b0b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = next(iter(test_load))[0].size()\n",
    "# torch.max(model(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2822d966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([9, 2, 1, 1, 6]),\n",
       " tensor([9, 2, 1, 1, 6]),\n",
       " tensor([0, 7, 7, 8, 5]),\n",
       " tensor([0, 7, 7, 8, 5]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X , y = next(iter(test_load))\n",
    "_, predicted = torch.max(model(X),1)\n",
    "predicted[:5] , y[:5] , predicted[-5:] , y[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d1b1cd",
   "metadata": {},
   "source": [
    "### 3ì°¨ì› ì»¬ëŸ¬ ì´ë¯¸ì§€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0677a3f0",
   "metadata": {},
   "source": [
    "#### RGB ì²´ë„ì˜ ê°ê°ì˜ í‰ê· ê³¼ í‘œì¤€í¸ì°¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d00722b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4914, 0.4822, 0.4465])\n",
      "tensor([0.2023, 0.1994, 0.2010])\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose( [transforms.ToTensor()] )\n",
    "\n",
    "test = torchvision.datasets.CIFAR10(root='./data' , train = True ,\n",
    "                                             download=True , transform=transform)\n",
    "\n",
    "\n",
    "mean = torch.zeros(3)\n",
    "std = torch.zeros(3)\n",
    "for data , _ in test:\n",
    "    mean += data.mean(dim=(1,2))\n",
    "    std += data.std(dim=(1,2))\n",
    "    # print(data[0].size())\n",
    "    # print(data[0].mean())# tensorì˜ í‰ê· \n",
    "    # print(data[0].mean(dim=(1,2))) # RGB í‰ê· \n",
    "    # print(data[0])\n",
    "print(mean / len(test))\n",
    "print(std / len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d144fc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.491401  , 0.48215896, 0.44653103], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(mean / len(test)).cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cb60bd",
   "metadata": {},
   "source": [
    "#### í•™ìŠµ / ê²€ì¦ / í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "056aa96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rgb_mean = mean / len(test)\n",
    "rgb_std = std / len(test)\n",
    "transform = transforms.Compose( [transforms.ToTensor(),\n",
    "                                 transforms.Normalize(rgb_mean , rgb_std)] )\n",
    "\n",
    "full_train_dataset = torchvision.datasets.CIFAR10(root='./data' , train = True ,\n",
    "                                             download=True , transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data' , train = False ,\n",
    "                                            download=True , transform=transform)\n",
    "\n",
    "from torch.utils.data import random_split\n",
    "# train/val ë¶„í•  : 8:2\n",
    "train_size = int(len(full_train_dataset)*0.8)\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "train_dataset , val_dataset = random_split(full_train_dataset , [train_size , val_size])\n",
    "\n",
    "\n",
    "\n",
    "train_load = DataLoader(train_dataset , batch_size=64 , shuffle=True)\n",
    "val_load = DataLoader(val_dataset , batch_size=64 , shuffle=False)\n",
    "test_load = DataLoader(test_dataset , batch_size=64 , shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72496fbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataset))[0].size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a7ce52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "for data in train_load:\n",
    "    print(data[0].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d02e375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 32, 32])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b84223",
   "metadata": {},
   "source": [
    "#### ì»¬ëŸ¬ì´ë¯¸ì§€ ì²˜ë¦¬ CNN ëª¨ë¸ì„ êµ¬í˜„\n",
    "- ì†ì‹¤í•¨ìˆ˜\n",
    "- ì˜µí‹°ë§ˆì´ì ¸\n",
    "- ìŠ¤ì¼€ì¤„ëŸ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d39e4425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸í´ë˜ìŠ¤\n",
    "# ì†ì‹¤í•¨ìˆ˜\n",
    "# ì—­ì „íŒŒë¥¼ ìœ„í•œ optimizer\n",
    "# í•™ìŠµë£¨í”„\n",
    "# í‰ê°€\n",
    "# ì˜ˆì¸¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "efb3699d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj (instance of CNN_CIFAR10) is not an instance or subtype of type (CNN).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m model \u001b[38;5;241m=\u001b[39m CNN()\n\u001b[1;32m     18\u001b[0m model\n\u001b[0;32m---> 20\u001b[0m cnn_cifar10_model \u001b[38;5;241m=\u001b[39m CNN_CIFAR10()\n\u001b[1;32m     21\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[41], line 3\u001b[0m, in \u001b[0;36mCNN_CIFAR10.__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28msuper\u001b[39m(CNN , \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()  \u001b[38;5;66;03m# 64, 3, 32, 32\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv2d(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m3\u001b[39m,padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mConv2d(\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m3\u001b[39m,padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj (instance of CNN_CIFAR10) is not an instance or subtype of type (CNN)."
     ]
    }
   ],
   "source": [
    "class CNN_CIFAR10(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN , self).__init__()  # 64, 3, 32, 32\n",
    "        self.conv1 = nn.Conv2d(3,32,3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(32,64,3,padding=1)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear( 64*8*8 ,128 )\n",
    "        self.fc2 = nn.Linear(128 , 10) #ì€ë‹‰ì¸µ\n",
    "    def forward(self ,  x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) # (64, 3, 32, 32)  ->  (64, 32, 16, 16)\n",
    "        x = self.pool(F.relu(self.conv2(x))) # (64, 32, 16, 16) -> (64, 64, 8, 8)\n",
    "        x = x.view(x.size(0) , -1)\n",
    "        x = F.relu(self.fc1(x)) \n",
    "        out = self.fc2(x)\n",
    "        return out\n",
    "\n",
    "model = CNN()\n",
    "model\n",
    "\n",
    "cnn_cifar10_model = CNN_CIFAR10()\n",
    "device = torch.device('cuda'  if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn_cifar10_model.parameters() , lr = 0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer , step_size=7 , gamma=0.1) #gamma : ë§¤ë²ˆ í•™ìŠµí• ë–„ë§ˆë‹¤(7epoch) lr*0.1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1a37d6",
   "metadata": {},
   "source": [
    "#### EarlyStopping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ccbfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self , patience = 5 , min_delta = 0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.count = 0\n",
    "        self.best_loss = float('inf')\n",
    "    def __call__(self , val_loss):\n",
    "        if val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True # ì¡°ê¸° ì¢…ë¥˜\n",
    "        return False\n",
    "early_stopping = EarlyStopping()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c1df9a",
   "metadata": {},
   "source": [
    "#### í›ˆë ¨ / ê²€ì¦ í•¨ìˆ˜ (accuracy í¬í•¨)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7940fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader , criterion , optimizer , device):\n",
    "    model.train() # dropoutì´ë‚˜ ë°°ì¹˜nomal ê¸°ëŠ¥ì„± ë ˆì´ì–´(ì¸µ)ì„ í™œì„±í™” ì‹œí‚´\n",
    "    # ì†ì‹¤ë¥ ì€ ê³„ì† ê³„ì‚°í•´ì•¼í•˜ê¸°ë–„ë¬¸ì— í•˜ê¸° ì½”ë“œì‘ì„±\n",
    "    runing_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    iterator = tqdm(enumerate(loader),total = len(loader) , desc='Train')\n",
    "    for batch_idx , (inputs , labels) in iterator:\n",
    "        inputs , labels = inputs.to(device) , labels.to(device)    \n",
    "        optimizer.zero_grad() # ê·¸ë ˆë””ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "        outputs = model(inputs) # ìˆœì „íŒŒ forward í˜¸ì¶œ --> ì˜ˆì¸¡\n",
    "        loss = criterion(outputs , labels) # ì†ì‹¤ê³„ì‚°\n",
    "        loss.backward() #ì—­ì „íŒŒ(ê·¸ë ˆì´ë˜íŠ¸(ê¸°ìš¸ê¸°) ê³„ì‚° -> ìë™ë¯¸ë¶„)\n",
    "        optimizer.step() # ì—­ì „íŒŒê°€ ì ìš© / ìœ„ë¡œ íƒ€ê³  ì˜¬ë¼ê°€ë©´ì„œ íŒŒë¼ë©”í„°(ê°€ì¤‘ì¹˜)ë¥¼ ì—…ë°ì´íŠ¸ì‹œì¼œì¤Œ\n",
    "        runing_loss += loss.item()\n",
    "\n",
    "        _ , predicted = torch.max(outputs.data,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()  #CPUë¡œ ê³„ì‹¼ê·¸ë˜í”„ì—ì„œ ë¹ ì§. (device GPUì—ì„œ í•¨)\n",
    "        iterator.set_postfix({'loss' : f'{loss.item():.3f}' , 'acc': f'{correct/total:.3f}'})\n",
    "    avg_loss = runing_loss / len(loader)\n",
    "    accuracy = correct / total\n",
    "    return avg_loss , accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f721fb",
   "metadata": {},
   "source": [
    "#### í›ˆë ¨ë£¨í”„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0448d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í›ˆë ¨ ë£¨í”„\n",
    "num_epochs = 20\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc =  train_epoch(cnn_cifar10_model,train_load,criterion,optimizer,device)\n",
    "    scheduler.step() # ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸\n",
    "    \n",
    "    # early stoppin check\n",
    "    if early_stopping(best_val_loss):\n",
    "        print(f'Early Stopping epoch : {epoch+1}')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc02c29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f593518",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.1 < float('inf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
